{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Of Titanic Survival\n",
    "**Author: Jason Schenck**    \n",
    "Date: January 30th 2017  \n",
    "CSC-570 Data Science Essentials\n",
    "\n",
    "\n",
    "\n",
    "* **[1 Introduction][Introduction]**\n",
    "   * [1.1][1.1] _Survival On The Titanic_\n",
    "   * [1.2][1.2] _Data Overview & Explanations_\n",
    "   * [1.3][1.3] _Exploratory Data Analysis (EDA) Defined_\n",
    "   * [1.4][1.4] _Process/Procedure & Methodology_\n",
    "* **[2 Feature Analysis][Feature Analysis]**\n",
    "   * [2.1][2.1] _Categorical/Nominal_\n",
    "     * [2.1.1][2.1.1] Survived\n",
    "     * [2.1.2][2.1.2] Pclass\n",
    "     * [2.1.3][2.1.3] Name\n",
    "     * [2.1.4][2.1.4] Sex\n",
    "     * [2.1.5][2.1.5] Ticket\n",
    "     * [2.1.6][2.1.6] Cabin\n",
    "     * [2.1.7][2.1.7] Embarked\n",
    "   * [2.2][2.2] _Continuous_\n",
    "     * [2.2.1][2.2.1] Age\n",
    "     * [2.2.2][2.2.2] SibSp\n",
    "     * [2.2.3][2.2.3] Parch\n",
    "     * [2.2.4][2.2.4] Fare\n",
    "     * [2.2.5][2.2.5] PassengerId\n",
    "   \n",
    "* **[3 Missing Values][Missing Values]**\n",
    "   * [3.1][3.1] _Variables Of Concern_\n",
    "     * [3.1.1][3.1.1] Age\n",
    "     * [3.1.2][3.1.2] Cabin\n",
    "   * [3.2][3.2] _Handling Of Missing Values_\n",
    "* **[4 Insights, Observations, and Questions][Insights]**\n",
    "   * [4.1][4.1] _Women & Children_\n",
    "   * [4.2][4.2] _Wealth vs Poverty_\n",
    "\n",
    "Data Source: [\"Kaggle: Titanic Machine Learning from Disaster\"](https://www.kaggle.com/c/titanic)\n",
    "   \n",
    "[Introduction]: #1-Introduction\n",
    "[1.1]: #1.1-Survival-On-The-Titanic\n",
    "[1.2]: #1.2-Data-Overview-&-Explanations\n",
    "[1.3]: #1.3-Exploratory-Data-Analysis-(EDA)-Defined\n",
    "[1.4]: #1.4-Process/Procedure-&-Methodology\n",
    "[Feature Analysis]: #2-Feature-Analysis\n",
    "[2.1]: #2.1-Categorical/Nominal\n",
    "[2.1.1]: #2.1.1-Survived\n",
    "[2.1.2]: #2.1.2-Pclass\n",
    "[2.1.3]: #2.1.3-Name\n",
    "[2.1.4]: #2.1.4-Sex\n",
    "[2.1.5]: #2.1.5-Ticket\n",
    "[2.1.6]: #2.1.6-Cabin\n",
    "[2.1.7]: #2.1.7-Embarked\n",
    "[2.2]: #2.2-Continuous\n",
    "[2.2.1]: #2.2.1-Age\n",
    "[2.2.2]: #2.2.2-SibSp\n",
    "[2.2.3]: #2.2.3-Parch\n",
    "[2.2.4]: #2.2.4-Fare\n",
    "[2.2.5]: #2.2.5-PassengerId\n",
    "[Missing Values]: #3-Missing-Values\n",
    "[3.1]: #3.1-Variables-Of-Concern\n",
    "[3.1.1]: #3.1.1-Age\n",
    "[3.1.2]: #3.1.2-Cabin\n",
    "[3.2]: #3.2-Handling-Of-Missing-Values\n",
    "[Insights]: #4-Insights,-Observations,-&-Questions\n",
    "[4.1]: #4.1-Women-&-Children\n",
    "[4.2]: #4.2-Wealth-vs-Poverty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My name is Jason Schenck, and I'm currently a graduate student at the University of Illinois at Springfield pursuing a MS CS degree with a focus mainly on data science, analytics, and artificial intelligence. This semester (Spring 2017) I was fortunate enough to gain entry to CSC570, Data Science Essentials, under the direction of Professor Mike Bernico who is an established practicing data scientist in the field. I'm very excited for the opportunity and wealth of knowledge that will surely be gained over the course of the next few months as I progress through this challenging semester!\n",
    "\n",
    "For my first assignment, I will be performing an exploratory data analysis on the Titanic dataset provided by Kaggle which contains observations of passengers who were aboard the ship at the time of sinking. Over the next 12 weeks I intend to build upon this study and construct a successful machine learning model which will be able to predict what sorts of people were likely to survive this tragedy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Survival On The Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle provides the following description of the challenge and analysis of this assignment:\n",
    "\n",
    ">The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    ">One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    ">In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Overview & Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable descriptions and details pertaining to the train and test datasets are provided by [**Kaggle**](https://www.kaggle.com/c/titanic/data):\n",
    "\n",
    "> \n",
    "<code>VARIABLE DESCRIPTIONS:\n",
    "survival        Survival\n",
    "                (0 = No; 1 = Yes)\n",
    "pclass          Passenger Class\n",
    "                (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "name            Name\n",
    "sex             Sex\n",
    "age             Age\n",
    "sibsp           Number of Siblings/Spouses Aboard\n",
    "parch           Number of Parents/Children Aboard\n",
    "ticket          Ticket Number\n",
    "fare            Passenger Fare\n",
    "cabin           Cabin\n",
    "embarked        Port of Embarkation\n",
    "                (C = Cherbourg; Q = Queenstown; S = Southampton)  \n",
    "SPECIAL NOTES:\n",
    "Pclass is a proxy for socio-economic status (SES)\n",
    " 1st ~ Upper; 2nd ~ Middle; 3rd ~ Lower  \n",
    "\n",
    ">Age is in Years; Fractional if Age less than One (1)\n",
    " If the Age is Estimated, it is in the form xx.5  \n",
    "With respect to the family relation variables (i.e. sibsp and parch)\n",
    "some relations were ignored.  The following are the definitions used\n",
    "for sibsp and parch.  \n",
    "\n",
    ">Sibling:  Brother, Sister, Stepbrother, or Stepsister of Passenger Aboard Titanic\n",
    "Spouse:   Husband or Wife of Passenger Aboard Titanic (Mistresses and Fiances Ignored)\n",
    "Parent:   Mother or Father of Passenger Aboard Titanic\n",
    "Child:    Son, Daughter, Stepson, or Stepdaughter of Passenger Aboard Titanic  \n",
    "\n",
    ">Other family relatives excluded from this study include cousins,\n",
    "nephews/nieces, aunts/uncles, and in-laws.  Some children travelled\n",
    "only with a nanny, therefore parch=0 for them.  As well, some\n",
    "travelled with very close friends or neighbors in a village, however,\n",
    "the definitions do not support such relations.</code>\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Exploratory Data Analysis (EDA) Defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An exploratory data analysis, or EDA, is the process of studying and learning about the data in our sample prior to testing a hypothesis. Each dependent variable is observed, classified, and inspected for relationships that may have an impact on the outcome of our dependent variable. In this case the dependent variable that we are trying to model prediction for is 'Survived', that is we are trying to determine which, if any, of our independent features of passengers have the highest influence over the outcome of whether or not a passenger was likely to survive or not at the time the Titanic sank. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Process/Procedure & Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To perform my EDA, I will inspect each variable/feature and first determine which variables are dependent versus independent and whether each one is categorical or continuous in nature. Then I will note the appropriate observations for each accordingly:\n",
    "\n",
    "* **For Categorical/Nominal Variables** \n",
    "  * What are the categories?  \n",
    "  * How many categories?\n",
    "  * Distribution analysis and visualization\n",
    "  * Are there any missing values?\n",
    "* **For Continuous Variables**\n",
    "  * Descriptive statistics: min, max, mean, standard deviation, etc.\n",
    "  * Distribution analysis and visualization\n",
    "  * Are there any missing values?\n",
    "* **For Both**\n",
    "  * What observations can be made from the distribution analysis?\n",
    "  * Can this variable be related in some way to any other idependent variable?\n",
    "  * Can this variable be related in some way to our dependent variable?\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Feature Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Categorical/Nominal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Required imports for Pandas and inline graph plots\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'train.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-39bbbf81c1bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a new dataframe 'df' by reading in our data file train.csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jasonschenck/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    644\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jasonschenck/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jasonschenck/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jasonschenck/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jasonschenck/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:4184)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:8449)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'train.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# Create a new dataframe 'df' by reading in our data file train.csv\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's take our first look at the data by printing the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inspect the 'shape' of the dataframe, print (# observations/rows, # variables/features/columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Survived' is a binary categorical feature that is going to play a major role in this analysis as it indicates whether a passenger survived or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ensure only two categories exist (Survived = 1 or Died = 0), and find the count of each.\n",
    "df.Survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualization of distribution of survivors(1) vs non-survivors(0)\n",
    "df.Survived.value_counts().plot(kind='barh', title=\"Survival Distribution (1 -> Yes, 0 -> No)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "df[df.Survived.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Survived' looks pretty good so far, as we would expect the analysis shows only two categories present 1 or 0 (survived, died), and we have no missing values which is great since it's crucial that we know for sure whether a passsenger survived or not. The value count and distribution tell us that most people didn't survive the sinking, which is also good news since that aligns with the actual event stats. I'm going to come back to 'Survived' later on to perform more observations and calculations since this is the dependent variable that I will be trying to model. With that in mind, I'm going to find the percentage of survival overall given 891 passengers in our sample and only 342 survived and store it for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finding & storing the total % Survival of all passengers\n",
    "survived_percent = 342/891.0\n",
    "print(survived_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary Survived**  \n",
    "Pretty straightforward here, this is the dependent variable of our study. Two categories: Did the passenger survive (1) or not (0)? From my EDA I conclude that it is a binary categorical feature. The distribution reflects approximately 38.38% of passengers in our sample survived which aligns with the historical population data of the actual event. Also, no missing values. I'll be looking more into 'Survived' again in my later section on insights/observations, for example considering the distribution of survival by gender, class, age, etc., but for now let's move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Pclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to our variable documentation, 'Pclass' should be a categorical variable which tells us which class a passenger was in: 1 - 1st, 2 - 2nd, or 3- 3rd class.  \n",
    "Let's test that real quick, and make sure everything looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ensure only 3 categories exist (1,2,3 class), and find the count of each.\n",
    "df.Pclass.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Since we have 3 categories this time, i'll check out a pie chart first\n",
    "df.Pclass.value_counts().plot(kind='pie', title='Distribution of Passenger Class (1st, 2nd, or 3rd)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# With class 1 and 2 being pretty close in value the pie chart was a bit difficult to interpret, plot bar as well.\n",
    "df.Pclass.value_counts().plot(kind='barh',title='Distribution of Passenger Class (1st, 2nd, or 3rd)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Any missing?\n",
    "df[df.Pclass.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This distribution looks interesting to me because we can see that an overwhelming majority of passengers appear to have been in 3rd class, yet there were more 1st class passengers than 2nd class passengers. Prior to visualization I would have expected the distribution to be in this order: 1st < 2nd < 3rd naturally. \n",
    "\n",
    "A few questions come to mind that I definitely want to investigate here. In regard to possible class and survival variable relationships, I'm going to calculate and store each class percent survived value.\n",
    "\n",
    "For me the elephant in the room here is 3rd class. What percent of the passengers did they represent? How did their majority representation play into the overall result of passenger survivorship on the Titanic? So many questions! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find and store distribution percent for each class\n",
    "class1_percent = len(df[df.Pclass == 1]) / 891.0\n",
    "class2_percent = len(df[df.Pclass == 2]) / 891.0\n",
    "class3_percent = len(df[df.Pclass == 3]) / 891.0\n",
    "print('Percent of 1st Class:',class1_percent)\n",
    "print('Percent of 2nd Class:',class2_percent) \n",
    "print('Percent of 3rd Class:',class3_percent)\n",
    "\n",
    "# More than 55% of all passengers were in 3rd class, that's more than 1st (~24%) and 2nd (~21%) combined!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find value counts of survived by class\n",
    "print('Survival By Class - Counts\\n')\n",
    "\n",
    "print('1st Class')\n",
    "class1_num_survived = df[df.Pclass == 1].Survived.value_counts()\n",
    "print(class1_num_survived,'\\n')\n",
    "\n",
    "print('2nd Class')\n",
    "class2_num_survived = df[df.Pclass == 2].Survived.value_counts()\n",
    "print(class2_num_survived,'\\n')\n",
    "\n",
    "print('3rd Class')\n",
    "class3_num_survived = df[df.Pclass == 3].Survived.value_counts()\n",
    "print(class3_num_survived,'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Survival by Class - Percent (342 total survivors)\n",
    "# What percentage of survivors were a particular class?\n",
    "class1_survived_percent = 136 / 342.0\n",
    "class2_survived_percent = 87 / 342.0\n",
    "class3_survived_percent = 119 / 342.0\n",
    "\n",
    "print('Survival - Pclass.Survived / Overall Survivors\\n')  \n",
    "print('1st Class')\n",
    "print(class1_survived_percent,'\\n')  \n",
    "\n",
    "print('2nd Class')\n",
    "print(class2_survived_percent,'\\n')\n",
    "\n",
    "\n",
    "print('3rd Class')\n",
    "print(class3_survived_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is definitely an area of very high concern! There were more than double the number of 3rd class passengers onboard the ship than 1st class passengers, yet even still despite those odds more 1st class passengers survived than 3rd.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary Pclass**  \n",
    "This variable is categorical, with 3 categories 1st, 2nd, or 3rd class. The distribution of passengers by Pclass was a very heavy majority of 3rd class passengers, accounting for more than than 1st and 2nd class combined! Upon closer inspection, this variable appears to be one of the most important factors affecting survival outcome so far! There were only ~24% of first class passengers meanwhile a whopping ~55% of the passengers were 3rd class, however when it comes to survival outcomes ~40% of 1st class passengers survived while only ~35% of 3rd class passengers survived.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4 Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.Sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.Sex.value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df.Sex=='female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df.Sex.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5 Ticket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.6 Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df.Cabin.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.7 Embarked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 SibSp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Parch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.Fare.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.Fare.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.Fare.hist(bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df.Fare.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df.Fare==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5 PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Displays the counts of each unique value for the feature \"PassengerId\"\n",
    "df.PassengerId.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As anticipated, we can see that this is definitely a continuous variable and probably does indeed only represent a unique identifier for each passenger. I also noticed that 'PassengerId' was not even included as a variable on the official description of the dataset provided by Kaggle above. Again just to be safe, I'll briefly take a look at the descriptive stats, distribution, and check for missing values next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Slice the id and perform stats\n",
    "df['PassengerId'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the distribution\n",
    "df.PassengerId.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if there are any missing values\n",
    "df[df.PassengerId.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PassengerId Summary**  \n",
    "Based on the analysis above, it can be concluded that this is simply a sequence of unique ID's for each passenger. This attribute was probably added to the dataset as a formality and means of organization. A 'PassengerId' starts at 1 and just increments in sequence to 891 with no meaningful distribution. This data is going to be irrelevant to our study and I would consider this an independent variable with no relationship or value to any other variables in our dataset or study. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Variables Of Concern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df.Cabin.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Handling Of Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Insights, Observations, & Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Women & Children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axs=plt.subplots(1,2)\n",
    "df[df.Sex=='male'].Survived.value_counts().plot('barh', ax=axs[0], title='Male Survivorship')\n",
    "df[df.Sex=='female'].Survived.value_counts().plot('barh', ax=axs[1], title = 'Female Survivorship')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df.Age<15].Survived.value_counts().plot('barh', title='Children Survivorship')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[another place]: www.github.com\n",
    "[another-link]: www.google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4.2 Wealth vs Poverty"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
