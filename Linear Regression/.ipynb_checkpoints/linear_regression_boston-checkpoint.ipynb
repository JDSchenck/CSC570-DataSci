{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jason Schenck\n",
    "#### Date: 02/13/16\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston Housing Assignment\n",
    "\n",
    "In this assignment you'll be using linear regression to estimate the cost of house in boston, using a well known dataset.\n",
    "\n",
    "Goals:\n",
    "+  Measure the performance of the model I created using $R^{2}$ and MSE\n",
    "> Learn how to use sklearn.metrics.r2_score and sklearn.metrics.mean_squared_error\n",
    "+  Implement a new model using L2 regularization\n",
    "> Use sklearn.linear_model.Ridge or sklearn.linear_model.Lasso \n",
    "+  Get the best model you can by optimizing the regularization parameter.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasonschenck/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bean = datasets.load_boston()\n",
    "print(bean.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_boston():\n",
    "    scaler = StandardScaler()\n",
    "    boston = datasets.load_boston()\n",
    "    X=boston.data\n",
    "    y=boston.target\n",
    "    X = scaler.fit_transform(X)\n",
    "    return train_test_split(X,y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a Linear Regression\n",
    "\n",
    "It's as easy as instantiating a new regression object (line 1) and giving your regression object your training data\n",
    "(line 2) by calling .fit(independent variables, dependent variable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a Prediction\n",
    "X_test is our holdout set of data.  We know the answer (y_test) but the computer does not.   \n",
    "\n",
    "Using the command below, I create a tuple for each observation, where I'm combining the real value (y_test) with\n",
    "the value our regressor predicts (clf.predict(X_test))\n",
    "\n",
    "Use a similiar format to get your r2 and mse metrics working.  Using the [scikit learn api](http://scikit-learn.org/stable/modules/model_evaluation.html) if you need help!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(20.399999999999999, 19.890594582524699),\n",
       " (13.1, 13.721248305563673),\n",
       " (10.800000000000001, 11.410207753360217),\n",
       " (17.699999999999999, 20.672868758671722),\n",
       " (21.399999999999999, 24.364416550830267),\n",
       " (15.6, 15.617517777743258),\n",
       " (43.799999999999997, 35.600427776912767),\n",
       " (23.800000000000001, 25.176264336397882),\n",
       " (11.800000000000001, 12.8287358982341),\n",
       " (25.0, 29.923767372244686),\n",
       " (22.800000000000001, 25.059633816787645),\n",
       " (26.199999999999999, 24.338188771678674),\n",
       " (32.200000000000003, 31.388681924472735),\n",
       " (15.1, 17.449968729960077),\n",
       " (18.399999999999999, 16.467001528469467),\n",
       " (29.100000000000001, 30.395083519334303),\n",
       " (14.4, 6.6383699100961735),\n",
       " (13.800000000000001, -0.98799661870104671),\n",
       " (23.0, 24.300793887277049),\n",
       " (11.9, 7.8115821797585792),\n",
       " (21.699999999999999, 19.789708241145323),\n",
       " (14.1, 16.272874978156324),\n",
       " (22.199999999999999, 25.695772080710739),\n",
       " (24.600000000000001, 25.134047168153014),\n",
       " (23.699999999999999, 28.316535000729971),\n",
       " (16.100000000000001, 22.524605457011894),\n",
       " (32.0, 34.327125675095083),\n",
       " (14.1, 19.147039579294905),\n",
       " (20.300000000000001, 22.923056556581976),\n",
       " (20.0, 22.00486872287836),\n",
       " (22.0, 22.315013064748484),\n",
       " (8.3000000000000007, 9.994873075264282),\n",
       " (18.199999999999999, 14.595428518768548),\n",
       " (21.899999999999999, 23.893836348328023),\n",
       " (24.800000000000001, 25.549565234704041),\n",
       " (20.699999999999999, 21.728943069725762),\n",
       " (35.100000000000001, 35.016924852042344),\n",
       " (6.2999999999999998, 10.003817423499401),\n",
       " (14.5, 18.079222734802048),\n",
       " (15.6, 20.894835580940104),\n",
       " (17.800000000000001, 8.1627539038774302),\n",
       " (21.600000000000001, 25.818121971793325),\n",
       " (12.800000000000001, 12.802462762124442),\n",
       " (26.600000000000001, 22.524696856984423),\n",
       " (13.6, 14.720969024978814),\n",
       " (28.0, 28.755263649664343),\n",
       " (39.799999999999997, 34.685270216792887),\n",
       " (29.399999999999999, 30.672480151148068),\n",
       " (28.399999999999999, 30.453151727372543),\n",
       " (33.399999999999999, 35.644618135566304),\n",
       " (50.0, 45.326269083934172),\n",
       " (36.5, 35.293860699688416),\n",
       " (20.399999999999999, 20.721870493498908),\n",
       " (18.5, 19.028500186497062),\n",
       " (21.399999999999999, 22.768747198209926),\n",
       " (5.0, 9.6199114389517248),\n",
       " (13.4, 13.113604752828085),\n",
       " (20.300000000000001, 18.754231940535956),\n",
       " (21.0, 21.087263286365044),\n",
       " (37.299999999999997, 35.113241027037517),\n",
       " (7.5, 13.305848558199083),\n",
       " (23.300000000000001, 26.27392536025706),\n",
       " (19.100000000000001, 17.357537343156032),\n",
       " (22.399999999999999, 22.775226596795509),\n",
       " (31.5, 31.511180586333722),\n",
       " (20.5, 20.65083810837622),\n",
       " (10.199999999999999, 5.4455340052162349),\n",
       " (19.399999999999999, 19.62146378928577),\n",
       " (27.100000000000001, 18.169166411601534),\n",
       " (24.800000000000001, 30.573608068096611),\n",
       " (34.899999999999999, 34.848043576984828),\n",
       " (19.600000000000001, 20.504170227123996),\n",
       " (33.799999999999997, 34.113189883405028),\n",
       " (27.0, 34.130263397490403),\n",
       " (22.800000000000001, 26.70867563099695),\n",
       " (46.700000000000003, 35.918771753998584),\n",
       " (23.899999999999999, 24.504346772960442),\n",
       " (10.9, 15.77143383464427),\n",
       " (27.899999999999999, 32.332944643971601),\n",
       " (14.6, 6.7726060218411828),\n",
       " (11.699999999999999, 16.880419282942388),\n",
       " (32.0, 33.293526902302503),\n",
       " (29.100000000000001, 31.557985058958806),\n",
       " (24.5, 21.240730101376062),\n",
       " (18.199999999999999, 18.488357941373849),\n",
       " (10.4, 17.15718009838934),\n",
       " (19.800000000000001, 22.862057284479484),\n",
       " (16.100000000000001, 18.86035350666759),\n",
       " (23.0, 24.032009750635066),\n",
       " (20.199999999999999, 16.219028680390977),\n",
       " (22.0, 28.579511295743401),\n",
       " (13.800000000000001, 20.77800992073853),\n",
       " (18.600000000000001, 16.774717667937775),\n",
       " (25.300000000000001, 25.265410096703775),\n",
       " (21.199999999999999, 23.27328544494685),\n",
       " (50.0, 43.324424437502486),\n",
       " (22.0, 21.114686278709812),\n",
       " (22.0, 27.22653289944828),\n",
       " (22.800000000000001, 29.314182067617669),\n",
       " (19.899999999999999, 20.43324022721437),\n",
       " (28.199999999999999, 32.58123527296901),\n",
       " (24.300000000000001, 19.927008026539372),\n",
       " (50.0, 40.452144189945642),\n",
       " (48.299999999999997, 37.762781010341556),\n",
       " (20.399999999999999, 23.042072914675817),\n",
       " (17.899999999999999, 0.63049216347024029),\n",
       " (18.100000000000001, 17.883217350580804),\n",
       " (29.600000000000001, 25.503909557302105),\n",
       " (19.699999999999999, 20.400830242618891),\n",
       " (21.100000000000001, 20.615184799916534),\n",
       " (48.799999999999997, 40.877280806296127),\n",
       " (13.199999999999999, 7.4608368702962551),\n",
       " (12.6, 18.627638324596798),\n",
       " (11.5, 14.055634884629248),\n",
       " (19.100000000000001, 24.369635774391934),\n",
       " (9.5, 13.008634748228541),\n",
       " (23.699999999999999, 28.32461088422702),\n",
       " (24.399999999999999, 23.715118947045983),\n",
       " (17.399999999999999, 16.895709329644898),\n",
       " (21.899999999999999, 40.029483375201941),\n",
       " (8.4000000000000004, 14.864116037715208),\n",
       " (35.200000000000003, 36.573183394946497),\n",
       " (20.300000000000001, 22.7197037718079),\n",
       " (18.899999999999999, 23.654577427681854),\n",
       " (23.100000000000001, 11.454665772012648),\n",
       " (24.800000000000001, 26.166876753863249),\n",
       " (24.399999999999999, 24.4841088011046)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip (y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task 1: Measure the performance of the model Professor Bernico created using  $R^{2}$   and MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store the predicted values for easier access\n",
    "y_predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the $R^{2}$ score, aka coefficient of determination, using sklearn.metrics.r2_score. An $R^{2}$ score is a value that ranges up to 1. The closer this value is 1, the more accurate our model is. In other words, the less error present between our predicted values (line of fit) and the actual values (y_test). From wikipedia:\n",
    ">\"In statistics, the coefficient of determination, denoted R2 or r2 and pronounced \"R squared\", is a number that indicates the proportion of the variance in the dependent variable that is predictable from the independent variable(s).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72726891273767869"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I will test the Mean Squared Error. From wikipedia:\n",
    "> \"In statistics, the mean squared error (MSE) or mean squared deviation (MSD) of an estimator (of a procedure for estimating an unobserved quantity) measures the average of the squares of the errors or deviations—that is, the difference between the estimator and what is estimated.\"\n",
    "\n",
    "The smaller an RMSE value, the closer predicted and observed values are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.340201656823584"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Implement new models using L2 regularization (Lasson & Ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape:  (379, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.05, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=True)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import for lasso model\n",
    "from sklearn import linear_model\n",
    "\n",
    "# To ensure fresh data, restore as fresh\n",
    "X_train, X_test, y_train, y_test = load_boston()\n",
    "print(\"Data Shape: \", X_train.shape)\n",
    "\n",
    "# From the sklearn doc, followed the recommended parameter setting. Adjusted alpha a few times however.\n",
    "clf_lasso = linear_model.Lasso(alpha=0.05, copy_X=True, fit_intercept=True, max_iter=1000,\n",
    "   normalize=False, positive=False, precompute=False, random_state=None,\n",
    "   selection='cyclic', tol=0.0001, warm_start=True)\n",
    "clf_lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared Score:  0.764486033667\n",
      "MSE Score:  19.8437462135\n"
     ]
    }
   ],
   "source": [
    "# Make predictions, zip together with actual y data for testing.\n",
    "y_pred_lasso = clf_lasso.predict(X_test)\n",
    "list(zip (y_test, y_pred_lasso))\n",
    "\n",
    "# Print out R and MSE scores\n",
    "print(\"R-Squared Score: \", r2_score(y_test, y_pred_lasso))\n",
    "print(\"MSE Score: \", mean_squared_error(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape:  (379, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.9997, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import for Ridge model\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# To ensure fresh data, restore as fresh\n",
    "X_train, X_test, y_train, y_test = load_boston()\n",
    "print(\"Data Shape: \", X_train.shape)\n",
    "\n",
    "# From the sklearn doc, followed the recommended parameter setting. Adjusted alpha a few times however.\n",
    "clf_ridge = Ridge(alpha=0.9997, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
    "clf_ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared Score:  0.802148948873\n",
      "MSE Score:  17.9035829556\n"
     ]
    }
   ],
   "source": [
    "# Make predictions, zip together with actual y data for testing.\n",
    "y_pred_ridge = clf_ridge.predict(X_test)\n",
    "list(zip (y_test, y_pred_ridge))\n",
    "\n",
    "# Print out R and MSE scores\n",
    "print(\"R-Squared Score: \", r2_score(y_test, y_pred_ridge))\n",
    "print(\"MSE Score: \", mean_squared_error(y_test, y_pred_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
