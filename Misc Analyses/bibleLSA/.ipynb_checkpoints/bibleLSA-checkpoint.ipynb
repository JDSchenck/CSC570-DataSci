{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Semantic Analysis:\n",
    "## _Data Mining for Meaningful Concepts In Christianity Newsgroups_\n",
    "---\n",
    "\n",
    "Prepared By: Jason Schenck  \n",
    "Date: February 6th 2017  \n",
    "CSC-570 Data Science Essentials\n",
    "\n",
    "\n",
    "<br>\n",
    "<big>Table Of Contents</big>\n",
    "\n",
    "---\n",
    "* **[1 Introduction][Introduction]**\n",
    "   * [1.1][1.1] _Purpose & Data Source_\n",
    "   * [1.2][1.2] _What is a \"Latent Semantic Analysis\"?_\n",
    "   * [1.3][1.3] _Terminology Defined_\n",
    "   * [1.4][1.4] _Process/Procedure & Methodology_\n",
    "\n",
    "\n",
    "* **[2 Data Preparation][Data Preparation]**\n",
    "   * [2.1][2.1] _Data Retrieval_\n",
    "   * [2.2][2.2] _Data Inspection_\n",
    "   * [2.3][2.3] _Defining 'stopwords'_\n",
    "\n",
    "\n",
    "* **[3 Latent Semantic Analysis (LSA)][Latent Semantic Analysis (LSA)]**\n",
    "   * [3.1][3.1] _TF-IDF Vectorization_\n",
    "   * [3.2][3.2] _SVD Modeling with Scikit-Learn_\n",
    "\n",
    "\n",
    "* **[4 Results: Interpration Of Extracted Concepts][Results: Interpration Of Extracted Concepts]**\n",
    "\n",
    "\n",
    "\n",
    "     \n",
    "[Introduction]: #1-Introduction\n",
    "[1.1]: #1.1-Purpose-&-Data-Source\n",
    "[1.2]: #1.2-What-is-a-\"Latent-Semantic-Analysis\"?\n",
    "[1.3]: #1.3-Terminology-Defined\n",
    "[1.4]: #1.4-Process/Procedure-&-Methodology\n",
    "[Data Preparation]: #2-Data-Preparation\n",
    "[2.1]: #2.1-Data-Retrieval\n",
    "[2.2]: #2.2-Data-Inspection\n",
    "[2.3]: #2.3-Defining-'stopwords'\n",
    "[Latent Semantic Analysis (LSA)]: #3-Latent-Semantic-Analysis-(LSA)\n",
    "[3.1]: #3.1-TF-IDF-Vectorization\n",
    "[3.2]: #3.2-SVD-Modeling-with-Scikit-Learn\n",
    "[Results: Interpration Of Extracted Concepts]: #4-Results:-Interpration-Of-Extracted-Concepts\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<html>\n",
    "<div class=\"alert alert-success\">\n",
    "<b>Data Source</b><a href=\"http://scikit-learn.org/stable/datasets/twenty_newsgroups.html#\">\"Twenty Newsgroups\", Provided By:<b> Scikit-Learn</b></b></a>\n",
    "</div>\n",
    "</html>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Purpose & Data Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this analysis I will be performing data mining in an effort to extract a series of meaningful and significant concepts from a public dataset of newsgroup postings on the topic of Christianity.\n",
    "\n",
    "The dataset, titled \"Twenty Newsgroups\" and is officially described as follows:\n",
    ">\"The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups. To the best of our knowledge, it was originally collected by Ken Lang, probably for his paper “Newsweeder: Learning to filter netnews,” though he does not explicitly mention this collection. The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.\"\n",
    "\n",
    "A newsgroup is an online public forum for discussion on a particular topic. The topic that I will be extracting data from will be \"Christianity\" (_soc.religion.christian_). I'm very curious to see what the results of this analysis will be, and in concluding intend to share my opinion on them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 What is a \"Latent Semantic Analysis\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Latent Semantic Analysis (LSA)_ is a technique commonly used in the field of Natural Language Processing (NLP). As a computer scientist, when performing NLP we are concerned with the interactions that that exist between computers and human language. A great portion of this field focuses on the analysis of the relationship between multiple words in a document of text contained in a collection of related documents. This is known as the subfield of _Natural Language Understanding_ and can be thought of more simply as \"teaching computers how to read\". \n",
    "\n",
    "LSA is more formally defined by [_\"An Introduction to Latent Semantic Analysis\" by Landauer, Foltz, & Laham_](http://lsa.colorado.edu/papers/dp1.LSAintro.pdf)\n",
    ">\"Latent Semantic Analysis (LSA) is a theory and method for extracting and representing the\n",
    "contextual-usage meaning of words by statistical computations applied to a large corpus of\n",
    "text (Landauer and Dumais, 1997). The underlying idea is that the aggregate of all the word\n",
    "contexts in which a given word does and does not appear provides a set of mutual\n",
    "constraints that largely determines the similarity of meaning of words and sets of words to\n",
    "each other.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Terminology Defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a vast list of new terminoloy defined by the field of NLP. Below I will briefly define those of significance to LSA which will be used extensively throughout this analysis.\n",
    "\n",
    "* **Bag Of Words (BOW)** - An abstraction model in NLP where we consider each document of text to simply be a \"bag of words\" in the literal sense, such that grammar and conceptual meaning is ignored.\n",
    "* **Term Frequency–Inverse Document Frequency (TF-IDF)** - A mathematical calculation for scoring the importance of a word in a document or a collection. This score value is based on _Zipf's Law_ of power distributions.\n",
    "* **Term** - A single word found in a document of text.\n",
    "* **Document** - A single collection of terms. Defined by the LSA study. In this case, each discussion post by a user will be a document.\n",
    "* **Corpus** - A single collection of related documents.\n",
    "* **Concept** - The final output of an LSA is a list of concepts. These are words, or multiple words together, which were found to have the highest significance across our corpus. They are called concepts, because they represent a meaningful 'conceptualization' that has been extracted from the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Process/Procedure & Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In brief, I will summarize a list of 7 steps representing the overall process required to perform an LSA:\n",
    "\n",
    "1. Collect/Retrieve a dataset containing text of interest. \n",
    "2. Define which text in the dataset will be represented as documents (sentences, discussion board poasts, news articles, ?)\n",
    "3. Using the BOW model, parse by document and store words in a BOW where each bag is a document. Ending result should be a collection of documents of terms.\n",
    "4. Clean the data by removing any non-alphanumeric characters such as HTML or XML tagging. Next, remove words that have very high frequency of repetition across the corpus, but with little to no significance. Due to the nature of 'TF-IDF' which relies on the _inverse_ frequency of significant terms across the corpus, this part of the process is not a straightforward one. Instead, by trial and error remove words with caution and sparingly, then re-test the model. This means steps 1-7 are completed, however you then must test and repeat this step possibly several times until the desired output is achieved. \n",
    "5. Perform TF-IDF Vectorization. This scores the words as terms for each document and across the corpus.\n",
    "6. Matrix decomposition using the SVD algorithm.\n",
    "7. Output a list of concepts extracted. \n",
    "\n",
    "Now we can begin our prepartions for LSA, starting with step 1, importing the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports, and dataset download via sk-learn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import re\n",
    "\n",
    "\n",
    "posts = open('ESV.dat', 'r').read()\n",
    "soup = BeautifulSoup(posts, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter the soup for only the values found between the <text> tags, rename the variable for ease of reading.\n",
    "postTxt = soup.decode_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "997"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many documents (forum posts) are in the dataset\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: sciysg@nusunix1.nus.sg (Yung Shing Gene)\\nSubject: Mission Aviation Fellowship\\nOrganization: National University of Singapore\\nLines: 3\\n\\nHi,\\n\\tDoes anyone know anything about this group and what they\\ndo? Any info would be appreciated. Thanks!\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first document\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: sciysg@nusunix1.nus.sg (Yung Shing Gene)\n",
      "Subject: Mission Aviation Fellowship\n",
      "Organization: National University of Singapore\n",
      "Lines: 3\n",
      "\n",
      "Hi,\n",
      "\tDoes anyone know anything about this group and what they\n",
      "do? Any info would be appreciated. Thanks!\n",
      "\n",
      "From: whitsebd@nextwork.rose-hulman.edu (Bryan Whitsell)\n",
      "Subject: Re: Satan and TV\n",
      "Reply-To: whitsebd@nextwork.rose-hulman.edu\n",
      "Organization: News Service at Rose-Hulman\n",
      "Lines: 14\n",
      "\n",
      "In article <May.9.05.41.06.1993.27543@athos.rutgers.edu>  \n",
      "salaris@niblick.ecn.purdue.edu (Rrrrrrrrrrrrrrrabbits) writes:\n",
      "> MTV controls what bands are popular, no matter how bad they are.  In fact, it is  \n",
      ">better to be politically correct - like U2, Madonna - than to have any musical  \n",
      ">talent. \n",
      "> Steven C. Salaris                \n",
      " \n",
      "Interesting idea.  \n",
      "Regular televeision seems to do this sort of thing too with politically correct  \n",
      "shows.\n",
      "\n",
      "\n",
      "In Christ's Love\n",
      "Bryan \n",
      "\n",
      "From: whitsebd@nextwork.rose-hulman.edu (Bryan Whitsell)\n",
      "Subject: Re: \"Accepting Jesus in your heart...\"\n",
      "Reply-To: whitsebd@nextwork.rose-hulman.edu\n",
      "Organization: Computer Science Department at Rose-Hulman\n",
      "Lines: 20\n",
      "\n",
      "stuff deleted ...\n",
      "\n",
      "> Religion (especially Christianity) is nothing more than a DRUG.\n",
      "> Some people use drugs as an escape from reality.  Christians inject\n",
      "> themselves with jeezus and live with that high. \n",
      " \n",
      "Your logic is falty.  If Christianity is a DRUG, and once we die we\n",
      "die, then why would you be reluctant to embrase this drug so that\n",
      "while you are alive you enjoy yourself.\n",
      "\n",
      "I also question your overall motives for posting this article.  Why\n",
      "would you waste your presious fews seconds on this earth posting your\n",
      "opinon to a group that will generally reject it.\n",
      "\n",
      "If you die, never having acepting Christ as your savior, I hope you\n",
      "have a fantastic life that it is all you evver dreamed because it is\n",
      "al of heaven you will ever know.\n",
      "\n",
      "In Christ's Love,\n",
      "Bryan\n",
      "\n",
      "From: e_p@unl.edu (edgar pearlstein)\n",
      "Subject: Legal definition of religion\n",
      "Organization: University of Nebraska--Lincoln\n",
      "Lines: 8\n",
      "\n",
      "\n",
      "  .\n",
      "           It's my understanding that the U.S. Supreme Court has never \n",
      "       given a legal definition of religion.  This despite the many \n",
      "       cases involving religion that have come before the Court. \n",
      "           Can anyone verify or falsify this?  \n",
      "           Has any state or other government tried to give a legal \n",
      "       definition of religion? \n",
      "\n",
      "From: aaron@binah.cc.brandeis.edu (Scott Aaron)\n",
      "Subject: Re: hate the sin...\n",
      "Reply-To: aaron@binah.cc.brandeis.edu\n",
      "Organization: Brandeis University\n",
      "Lines: 46\n",
      "\n",
      "In article <May.12.04.27.07.1993.9920@athos.rutgers.edu>, scott@prism.gatech.edu (Scott Holt) writes:\n",
      ">\"Hate the sin but love the sinner\"...I've heard that quite a bit recently, \n",
      ">often in the context of discussions about Christianity and homosexuality...\n",
      ">but the context really isn't that important. My question is whether that\n",
      ">statement is consistent with Christianity. I would think not.\n",
      ">\n",
      ">Hate begets more hate, never love. Consider some sin. I'll leave it unnamed\n",
      ">since I don't want this to digress into an argument as to whether or not \n",
      ">something is a sin. Now lets apply our \"hate the sin...\" philosophy and see\n",
      ">what happens. If we truly hate the sin, then the more we see it, the \n",
      ">stronger our hatred of it will become. Eventually this hate becomes so \n",
      ">strong that we become disgusted with the sinner and eventually come to hate\n",
      ">the sinner. In addition, our hatred of the sin often causes us to say and \n",
      ">do things which are taken personally by the sinner (who often does not even \n",
      ">believe what they are doing is a sin). After enough of this, the sinner begins\n",
      ">to hate us (they certainly don't love us for our constant criticism of their\n",
      ">behavior). Hate builds up and drives people away from God...this certainly\n",
      ">cannot be a good way to build love.\n",
      "\n",
      "I don't agree, but I can only speak for myself.  I have a good friend\n",
      "whose lifestyle is very sinful.  Do I hate the things she does to herself\n",
      "and others?  Yes.  Do I hate her?  Absolutely not.  In fact, she tells me\n",
      "repeatedly that I am the best friend she has in the world.  I care about\n",
      "her very much despite the fact that I hate how she lives her life.\n",
      "\n",
      "It's very easy to fall into the progression you describe above.  I've\n",
      "felt it with my friend more than once.  There is a very important \n",
      "part of Christianity that you've overlooked above and makes it possible\n",
      "to \"love the sin but hate the sinner.\"  Before I look at someone\n",
      "else's life and sin, I look to myself and am as disgusted by what I see\n",
      "in *me* as I see in others, probably more.  Self-righteousness is\n",
      "contradictory to Christianity and is what makes the progression you\n",
      "describe happen.  If a Christian can truthfully quote Paul and say, \"Wretched\n",
      "man that I am!\" [Romans 7:24 (NASB)], that Christian will be able\n",
      "to love the sinner and hate the sin.  If we have the attitude of the Pharisee \n",
      "who said, \"I thank Thee that I am not like other men...\" [Luke 18:11 (NASB)],\n",
      "we will hate both.\n",
      "\n",
      "  -- Scott at Brandeis\n",
      "\n",
      "\t\"But God demonstrates His     \"The Lord bless you, and keep you;\n",
      "\t own love for us, in that      the Lord make His face shine on you,\n",
      "\t while we were yet sinners,    and be gracious to you;\n",
      "\t Christ died for us.\"\t       the Lord lift up His countenance on you,\n",
      "\t\t\t\t       and give you peace.\"\n",
      "\t\t-- Romans 5:8 [NASB]\t\t-- Numbers 6:24-26 [NASB]\n",
      "\n",
      "From: qtm2w@virginia.edu (Quinn T. McCord)\n",
      "Subject: Questions from a newbie\n",
      "Organization: University of Virginia\n",
      "Lines: 56\n",
      "\n",
      "\n",
      "\tIs life a pass/fail course, and does God grade on a\n",
      "curve?\n",
      "\tI'm new here, and only vaguely religious, but I want to\n",
      "know what some of you people think.  Specifically, are there an\n",
      "infinite number of Heavens, and a person goes to the one that\n",
      "he/she deserves?  Or is it simply Heaven or nothing (Hell?)\n",
      "Also, are we \"graded\" by those around us, or has there always\n",
      "been some unchanging method?  Is the person's childhood taken\n",
      "into account?\n",
      "\tI'm sure these must sound like over-simplifications to\n",
      "most of you, but I figure that you're the experts.\n",
      "\n",
      "\t\t\t\t\t\t-Quinn\n",
      "\n",
      "[Eschatology is an area on which Christians do not agree.  I suspect\n",
      "that's because our primary source of information is prophets and\n",
      "visionaries, and their writings tend to be highly symbolic.  However\n",
      "both Jesus' teachings in the Gospels and books such as the Revelation\n",
      "to John talk primarily about the difference between eternal life and\n",
      "eternal death.  On a number of occasions Jesus does say things that\n",
      "imply some sort of differentiation, e.g. Lk 10:14 and a number of\n",
      "similar passages where Jesus says things like \"even XXX will be better\n",
      "off than you in the judgement.\"  Also, I Cor 3 talks about someone who\n",
      "gets into heaven, but by the skin of his teeth, as it were.  But these\n",
      "passages are not normally interpreted as suggesting separate heavens,\n",
      "so much as differing levels of prestige or punishment in heaven or\n",
      "hell (and not all Christians would even go as far as that).  The only\n",
      "Christian group I know of that believes in multiple heavens is the\n",
      "Mormons, and they are very far from mainstream Christianity (far\n",
      "enough that many of our readers would not call them Christian).  Their\n",
      "ideas in this area involve specific Mormon revelations, in addition\n",
      "to the Bible and \"Holy Tradition\" of a more generic Christian sort.\n",
      "\n",
      "Note that many Christians will cringe at the very thought of\n",
      "associating grading with God.  The whole point of Christ was to free\n",
      "us from the results of a test that we couldn't possibly pass.  If you\n",
      "like test analogies, God grades on a very strict and unbending scale,\n",
      "but he also cheats -- he replaces our test papers with an exam that\n",
      "was prepared by the teacher, before actually doing the grading.\n",
      "Because some people end up in heaven and others in hell, it's easy to\n",
      "see why you'd be inclined to think of it as grading.  While there are\n",
      "differences among branches of Christianity on details, I think we all\n",
      "agree that in one way or another, God cheats.\n",
      "\n",
      "I am personally very sceptical about anyone who claims to know exactly\n",
      "how far God's cheating extends.  Will he accept people who don't\n",
      "explicitly acknowledge Christ, but somehow still follow him in their\n",
      "hearts?  Many Christians believe that this is possible, at least in\n",
      "principle, but certainly not all do.  Jesus provided us with a clear\n",
      "description of how to be saved, but it's not clear to me that he\n",
      "provided an exact description of how he's going to place the dividing\n",
      "line.  Certainly he made it clear that we can't expect to know whether\n",
      "other individuals are saved or not.\n",
      "\n",
      "--clh]\n",
      "\n",
      "From: JEK@cu.nih.gov\n",
      "Subject: tongues (read me!)\n",
      "Lines: 8\n",
      "\n",
      "Persons interested in the tongues question are are invited to\n",
      "peruse an essay of mine, obtainable by sending the message\n",
      " GET TONGUES NOTRANS\n",
      " to LISTSERV@ASUACAD.BITNET or to\n",
      "    LISTSERV@ASUVM.INRE.ASU.EDU\n",
      "\n",
      " Yours,\n",
      " James Kiefer\n",
      "\n",
      "From: mdw33310@uxa.cso.uiuc.edu (Michael D. Walker)\n",
      "Subject: Re: Question about Virgin Mary\n",
      "Organization: University of Illinois at Urbana\n",
      "Lines: 19\n",
      "\n",
      "\n",
      "\tTwo follow up's to Mark's last posting:\n",
      "\n",
      "\t1.  As far as current investigations, the Church recently declared the\n",
      "\t    crying statue and corresponding messages from Mary at Akita,\n",
      "\t    Japan as approved (I found this out about a month ago.)\n",
      "\n",
      "\t2.  Again in the proof department, start with the appearances of Mary\n",
      "\t    at Fatima.  Among other things, there were pictures taken of the\n",
      "\t    \"miracle of the sun\" that appeared in some major American newspaper\n",
      "\t    (The New York Times, I believe) as well as most of the major\n",
      "\t    European newspapers.  \n",
      "\n",
      "\t    I could talk (or post) for hours on this topic, but... \n",
      "\t\t(I have a thesis to write).\n",
      "\t\t\t\t\t\tGod Bless,\n",
      "\t\t\t\t\t\t\t- Mike Walker\n",
      "\t\t\t\t\t\t\t \n",
      "P.S.  Anyone want info, I have more.  mdw33310@uxa.cso.uiuc.edu\n",
      "\n",
      "From: jkellett@netcom.com (Joe Kellett)\n",
      "Subject: Re: Opinions asked about rejection\n",
      "Organization: Netcom\n",
      "Lines: 22\n",
      "\n",
      "William Mayne (mayne@pipe.cs.fsu.edu) wrote:\n",
      ": In article <Apr.1.02.34.21.1993.21547@athos.rutgers.edu> jayne@mmalt.guild.org (Jayne Kulikauskas) writes:\n",
      "\n",
      ": >People who reject God don't want to be wth Him in heaven.  We spend our \n",
      ": >lives choosing to be either for Him or against Him.  God does not force \n",
      ": >Himself on us.\n",
      "\n",
      ": I must say that I am shocked. My impression has been that Jayne Kulikaskas\n",
      ": usually writes this much less offensive and ludicrous than this. I am not\n",
      ": saying that the offensiveness is intentional, but it is clear and it is\n",
      ": something for Christians to consider.\n",
      "\n",
      "Jayne stands in pretty good company.  C.S. Lewis wrote a whole book\n",
      "promoting the idea contained in her first sentence quoted above.  It is\n",
      "called \"The Final Divorce\".  Excellent book on the subject of Heaven and\n",
      "Hell, highly recommended.  It's an allegory of souls who are invited, indeed\n",
      "beseeched to enter Heaven, but reject the offer because being with God in\n",
      "Heaven means giving up their false pride.\n",
      "\n",
      "-- \n",
      "Joe Kellett\n",
      "jkellett@netcom.com\n",
      "\n",
      "From: Eugene.Bigelow@ebay.sun.com (Geno )\n",
      "Subject: Re: The doctrine of Original Sin\n",
      "Reply-To: Eugene.Bigelow@ebay.sun.com\n",
      "Organization: Sun Microsystems, Inc.\n",
      "Lines: 10\n",
      "\n",
      "Joseph H. Buehler writes:\n",
      "\n",
      ">This all obviously applies equally well to infants or adults, since\n",
      ">both have souls.  Infants must be baptized, therefore, or they cannot\n",
      ">enter into Heaven.  They too need this form of life in them, or they\n",
      ">cannot enter into Heaven.\n",
      "\n",
      "Are you saying that baptism has nothing to do with asking Jesus to come into\n",
      "your heart and accepting him as your savior, but is just a ritual that we\n",
      "must go through to enable us to enter Heaven?\n",
      "\n",
      "From: carlson@ab24.larc.nasa.gov (Ann Carlson)\n",
      "Subject: Re: Homosexuality issues in Christianity\n",
      "Organization: NASA Langley Research Center, Hampton, VA  USA\n",
      "Lines: 26\n",
      "\n",
      "In article <May.7.01.08.16.1993.14381@athos.rutgers.edu>, whitsebd@nextwork.rose-hulman.edu (Bryan Whitsell) writes:\n",
      "|> Any one who thinks that Homosexuality and Christianity are compatible should check  \n",
      "|> out:\n",
      "|> \tRomans 1:27\n",
      "|> \tI Corinthians 6:9\n",
      "|> \tI Timothy 1:10\n",
      "|> \tJude 1:7\n",
      "|> \tII Peter 2:6-9\n",
      "|> \tGen. 19\n",
      "|> \tLev  18:22\n",
      "|> (to name a few of the verses that pertain to homosexuality)\n",
      "\n",
      "Anyone who thinks being gay and Christianity are not compatible should \n",
      "check out Dignity, Integrity, More Light Presbyterian churches, Affirmation,\n",
      "MCC churches, etc.  Meet some gay Christians, find out who they are, pray\n",
      "with them, discuss scripture with them, and only *then* form your opinion.\n",
      "-- \n",
      "\n",
      "\n",
      "\n",
      "*************************************************      \n",
      "*Dr. Ann B. Carlson (a.b.carlson@larc.nasa.gov) *       O .\n",
      "*MS 366                                         *         o  _///_ //\n",
      "*NASA Langley Research Center                   *          <`)=  _<<\n",
      "*Hampton, VA 23681-0001                         *             \\\\\\  \\\\\n",
      "*************************************************\n",
      "\n",
      "From: hayesstw@risc1.unisa.ac.za (Steve Hayes)\n",
      "Subject: Re: Hyslop and _The_Two_Babylons_\n",
      "Organization: University of South Africa\n",
      "Lines: 52\n",
      "\n",
      "In article <May.13.02.30.57.1993.1557@geneva.rutgers.edu> mangoe@cs.umd.edu (Charley Wingate) writes:\n",
      "\n",
      ">Seeing as how _The_Two_Babylons_ has been brought up again, it is time for\n",
      ">me to respond , once again, and say that this book is junk.  It is nothing\n",
      ">more that an anti-Catholic tract of the sort published ever since the there\n",
      ">were protestants.  Its scholarship is phony and its assertions spurious.\n",
      "\n",
      "\n",
      "I have not seen this book, though I have had several people quote it in \n",
      "support of some tendentious assertions they were making, so I have become \n",
      "curious about it.\n",
      "\n",
      "I don't want to malign this Hislop fellow, whoever he may be, as I have only \n",
      "heard the arguments at second hand, but both of the arguments seemed to turn \n",
      "on false etymology that SEEMED to be derived from Hislop.\n",
      "\n",
      "I would be interested in knowing more about these things. \n",
      "\n",
      "The first one claimed that the word \"church\" was derived from the Greek \n",
      "\"cyclos\", and that it was therefore related to the worship of \"Circe\".\n",
      "\n",
      "I don't know if Hislop is the source of this assertion, but it does seem to \n",
      "be based on false etymology.\n",
      "\n",
      "The second claimed an etymological relationship between \"Ishtar\" and \n",
      "\"Easter\", which seemed to be even more fanciful and far-fetched than some \n",
      "of the wilder notions of the British Israelites.\n",
      "\n",
      "Regarding the latter, as far as I have been able to find out, \"Easter\" is \n",
      "derived from the old English name for April - \"Eosturmonath\". The Venerable \n",
      "Bede mentioned that this was associated with a goddess called \"Eostre\", but \n",
      "apart from that reference I have not been able to find out anything more \n",
      "about her. It also seems that the term \"Easter\" is only used by the English \n",
      "and those they evangelized. The Germans, for example, also use the term \n",
      "\"Ostern\", but Germany was evangelized by English missionaries.\n",
      "\n",
      "So I would be interested in any evidence of \"Easter\" being used for Pascha \n",
      "by people who do not have any kind of connection with the ancient Anglo-\n",
      "Saxons and their offshoots. Such evidence might support the claims of those \n",
      "who appear to derive the theory from Hislop.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "Steve Hayes, Department of Missiology & Editorial Department\n",
      "Univ. of South Africa, P.O. Box 392, Pretoria, 0001 South Africa\n",
      "Internet: hayesstw@risc1.unisa.ac.za         Fidonet: 5:7101/20\n",
      "          steve.hayes@p5.f22.n7101.z5.fidonet.org\n",
      "FAQ: Missiology is the study of Christian mission and is part of\n",
      "     the Faculty of Theology at Unisa\n",
      "\n"
     ]
    }
   ],
   "source": [
    " #Uncomment this block to inspect a sample of 10 documents *\n",
    "# Print the first 10 documents to inspect the data\n",
    "for x in range(0,12):\n",
    "    print(corpus[x])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**  \n",
    "It appears our data is in plain text with no tagging. However, each post starts with a heading which I've noticed is also variable across the corpus. For example some posts start with a header containing \"From\", \"Subject\", and \"Organization\" while others do not. The following headers are present across the corpus:  \n",
    "* **From:** [ _email@emailaddress.com_ ]\n",
    "* **Subject:** [ _topic_ ]\n",
    "* **Reply-To:** [ _email@emailaddress.com_ ]\n",
    "* **Organization:** [ _Organization Name_ ]\n",
    "* **Lines:** [ _# Lines of post_ ]\n",
    "\n",
    "Also, it appears that a post can be from either a public individual or a member of an organization. In either case, posts can also be both new posts or replies to other's posts. Every header ends with \"Lines:\" which tells us the number of lines of text contained in the post message itself.\n",
    "\n",
    "\n",
    "Post content looks like it could be problemsome for LSA if I don't carefully define the stopset of exclusion words. I found that this part of the process consisted of stopset defining and repetitive model testing in order to fine-tune the results.   \n",
    "\n",
    "One thing that I know we are going to want to exclude regardless are e-mail addresses because these items appear across the entire corpus, and therefore will decrease model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: \n",
      "Subject: tongues (read me!)\n",
      "Lines: 8\n",
      "\n",
      "Persons interested in the tongues question are are invited to\n",
      "peruse an essay of mine, obtainable by sending the message\n",
      " GET TONGUES NOTRANS\n",
      " to  or to\n",
      "    \n",
      "\n",
      " Yours,\n",
      " James Kiefer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using regex, find and remove all e-mail addresses in all documents across the entire corpus\n",
    "corpus = [re.sub(r'(\\s)(\\S+\\@\\S+)(\\s)', r'\\1\\3', corpus[x]) for x in range(len(corpus))]\n",
    "\n",
    "# Check it\n",
    "print(corpus[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from: \n",
      "subject: tongues (read me!)\n",
      "lines: 8\n",
      "\n",
      "persons interested in the tongues question are are invited to\n",
      "peruse an essay of mine, obtainable by sending the message\n",
      " get tongues notrans\n",
      " to  or to\n",
      "    \n",
      "\n",
      " yours,\n",
      " james kiefer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert all text to lower-case\n",
    "postDocs = [x.lower() for x in corpus]\n",
    "\n",
    "# Check it\n",
    "print(postDocs[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Defining 'stopwords'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have removed all of the email addresses and formatted the text to lower-case, I will define the stopset. \n",
    "\n",
    "A 'stopset' is a list of 'stopwords' which will be excluded from analysis automatically by scikit-learn's vectorization algorithm. For this LSA, I'm going to use a combination of two pre-built lists for the first attempt: a stopset provided by _Natural Language Toolkit(NTLK)_, and one that I found online called the _Terrier stopset_.\n",
    "\n",
    "In order to combine these two, we store them in a 'set' datastructure and perform a 'union' between them removing duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jasonschenck/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import NTLK stopset\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use this cell to add new exclusion words to the stopset before and/or after model testing.\n",
    "# Note: Most of the words below were added over the course of numerous output testing efforts.\n",
    "\n",
    "stopset = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "\n",
    "stopset.update(['mercury','san','christiansen','dozier','athens','josh','0001','jose','lois','perry','department','editorial','etc','0358','542','706','30602','nasa','langley','subject','elizabeth'\n",
    "                'phone','bell','nova','gmi','khan0095','budd','28','bud','nj','wkuvx1','bitnet','easteee','holt','gatech','carol','howard','len','hampton','va','cs','terrance','acad1','sahs','uth','randerso','larc','gov','whitesbsd','nextwork','trol','eeap','apr',\n",
    "                'r2d2','vbv','n4tmi','wbt','wycliffe','ata','hfsi','uk','fidonet','jeff','fenholt','indiana','fisher','microsystems','creps','alvin','netcom','andrew','fil','revdak','jr','velasco',\n",
    "                'virgilio','ac','za','hayesstw','risc1','ucs','lee','nicholas','mandock','randal','overacker','larry','bernard','elizabeth','dean','seanna','unisa','rose','bryan','bnr','jayne','heath','scott','llo','acs','vela','atterlep',\n",
    "                'lines','petch','carlson','caralv','university','georgia','aisun3','reply-to','organization','hulman','hayes','steve','mcovingt','ai','ca','covington','bigelow','eugene','tek','gvg47','chuck','gvg','com','uga','bernadette','rutgers',\n",
    "                'edu','quot','spacing','text','line','none','sans','line','title','word', 'neue','johnsd2','rpi','mls','panix','ebay','group','freenet','carleton','ncr','cso','uxa','uiuc','bjorn','elsegundoca','mit','koberg','gt7122b','oo','la','microsoft','kuhub','cc','ukans',\n",
    "                'fnal','marka','csd','sapienza','lady','posting','rolfe','joe','jon','tom','fred','ling','siew','wee','matt5','lest','bill','wager','oakland','rochester','alan','steele','therefore','todd','aaron','bryce','a888','sledd','stan','pretoria','392','commentary',\n",
    "                'cox','paz','vic','fax','713','703','3729','827','murray','dale','gary','reply','mail','gerry','tx','shall','245','shell','box','univ','aa888','traer','bruce','__','___','601','22102','708','632','trei','eggert','amateur','radio','company','houston','lincoln','408',\n",
    "                '241','9760','02173','617','244','st','203','617','981','2575','subject','really','number','quite','loisc','article','baker','ashley','sj','see'])\n",
    "\n",
    "# Potential bible verse references, originally added and then removed from stopset\n",
    "# '44','31','10','11','31','14','21'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the Terrier stopset from file, union with existing stopset\n",
    "terrierstopset = open('terrierstopset.txt', 'r').read()\n",
    "stopset = set(stopset).union(set(terrierstopset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Latent Semantic Analysis (LSA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this process, I'll be using the TfidfVectorizer() function from the scikit-learn library. This is the part of the LSA that actually converts the words of text that we have collected in to numerical representations by assigning them TF-IDF scores. \n",
    "> _ The TF-IDF score of a word 'w' is:_  \n",
    "> \n",
    "> $$tf(w) * idf(w)$$\n",
    ">\n",
    "> _where: $$tf(w) =\\frac{\\text{number of times a word appears in the doc}}{\\text{total number of words in the doc}}$$_ \n",
    ">\n",
    "> and : $$idf(w)=  \\left\\{log\\frac{\\text{number of documents}}{\\text{number of documents that contain the word w}}\\right\\}$$\n",
    "\n",
    "When we vectorize, we are essentially defining a lexical analyzer that is built into scikit-learn and therefore must specify some important parameters:  \n",
    "\n",
    "* **stopwords:** set the param to var stopset  \n",
    "<br>\n",
    "* **use idf:** always set to true for LSA  \n",
    "<br>\n",
    "* **ngram range:** 'grams' are words, and the ngram_range specifies to the analyzer the minimum(1) to the maximum(N) grams to consider for contextual relationships. I originally started this analysis with ngram_range=(1,3), however found through serveral rounds of testing and fine-tuning that (2,5) tends to produce the most optimal results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the vectorizer model\n",
    "vectorizer = TfidfVectorizer(stop_words=stopset, use_idf=True, ngram_range=(2, 4),smooth_idf=True)\n",
    "\n",
    "# Fit the corpus data\n",
    "X = vectorizer.fit_transform(postDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 420714)\t0.158640819949\n",
      "  (0, 338335)\t0.158640819949\n",
      "  (0, 152859)\t0.158640819949\n",
      "  (0, 243857)\t0.158640819949\n",
      "  (0, 39327)\t0.158640819949\n",
      "  (0, 141944)\t0.158640819949\n",
      "  (0, 251236)\t0.138487062613\n",
      "  (0, 343183)\t0.158640819949\n",
      "  (0, 175992)\t0.143395091067\n",
      "  (0, 28432)\t0.115840647931\n",
      "  (0, 205145)\t0.131086376814\n",
      "  (0, 28878)\t0.158640819949\n",
      "  (0, 189799)\t0.158640819949\n",
      "  (0, 412636)\t0.138487062613\n",
      "  (0, 31117)\t0.138487062613\n",
      "  (0, 420715)\t0.158640819949\n",
      "  (0, 338336)\t0.158640819949\n",
      "  (0, 152860)\t0.158640819949\n",
      "  (0, 243858)\t0.158640819949\n",
      "  (0, 39328)\t0.158640819949\n",
      "  (0, 141945)\t0.158640819949\n",
      "  (0, 251245)\t0.158640819949\n",
      "  (0, 343184)\t0.158640819949\n",
      "  (0, 175993)\t0.143395091067\n",
      "  (0, 28435)\t0.149722640257\n",
      "  (0, 205149)\t0.158640819949\n",
      "  (0, 28879)\t0.158640819949\n",
      "  (0, 189800)\t0.158640819949\n",
      "  (0, 412639)\t0.143395091067\n",
      "  (0, 420716)\t0.158640819949\n",
      "  (0, 338337)\t0.158640819949\n",
      "  (0, 152861)\t0.158640819949\n",
      "  (0, 243859)\t0.158640819949\n",
      "  (0, 39329)\t0.158640819949\n",
      "  (0, 141946)\t0.158640819949\n",
      "  (0, 251246)\t0.158640819949\n",
      "  (0, 343185)\t0.158640819949\n",
      "  (0, 175994)\t0.149722640257\n",
      "  (0, 28436)\t0.158640819949\n",
      "  (0, 205150)\t0.158640819949\n",
      "  (0, 28880)\t0.158640819949\n",
      "  (0, 189801)\t0.158640819949\n"
     ]
    }
   ],
   "source": [
    "# Tada! This is now the output of the first document in the corpus, in sparse IDF matrix form.\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(997, 420957)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The current shape is (documents, terms)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 SVD Modeling with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Single Value Decomposition** (SVD) is the process of taking our corpus of matrices (X), and performing _matrix decomposition_ such that:\n",
    "\n",
    "<big>$$X \\approx USV^{T}$$</big>\n",
    "\n",
    "where...\n",
    "\n",
    "* **X** = Original corpus matrix\n",
    "* **m** = Number of documents contained in X\n",
    "* **n** = Number of terms\n",
    "<br>\n",
    "\n",
    " \n",
    "**_X is decomposed into three matricies called U, S, and T with k-value such that..._**  \n",
    "\n",
    "\n",
    "\n",
    ">* **k** = Number of concepts we want to mine for\n",
    ">\n",
    ">\n",
    ">* **U** = An {'_m x k_'} matrix.  \n",
    ">  * _Rows_ = Documents\n",
    ">  * _Columns_ = Concepts\n",
    ">* **S** = A {'_k x k_'} diagonal matrix. \n",
    ">  * _Elements_ =  Variation captured from each concept.\n",
    ">* **V** = An {'_n x k_'} matrix.\n",
    ">  * _Rows_ = Terms\n",
    ">  * _Columns_ = Concepts\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an advanced mathematical procedure involving linear algebra which will decompose our matrix X into three U,S,& V. The entire process is built-in to scikit-learn as an engine model, all we must do is define the model specifications and let it do the work for us. \n",
    "\n",
    "[**scikit-learn**](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html) provides the following documentation on this function:  \n",
    "> \"Dimensionality reduction using truncated SVD (aka LSA).\n",
    "This transformer performs linear dimensionality reduction by means of truncated singular value decomposition (SVD). Contrary to PCA, this estimator does not center the data before computing the singular value decomposition. This means it can work with scipy.sparse matrices efficiently.\n",
    "In particular, truncated SVD works on term count/tf-idf matrices as returned by the vectorizers in sklearn.feature_extraction.text. In that context, it is known as latent semantic analysis (LSA).\n",
    "This estimator supports two algorithms: a fast randomized SVD solver, and a “naive” algorithm that uses ARPACK as an eigensolver on (X * X.T) or (X.T * X), whichever is more efficient.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=100, n_iter=5,\n",
       "       random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the TruncatedSVD model\n",
    "\n",
    "# Params: n_components=100 for LSA per sk-learn doc, n_iter=5 (default, and should be adjusted during testing) \n",
    "lsa = TruncatedSVD(n_components=100, n_iter=5)\n",
    "\n",
    "# Fit the model\n",
    "lsa.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.45641047e-06,   5.45641047e-06,   5.45641047e-06, ...,\n",
       "         2.02826051e-05,   2.02826051e-05,   2.02826051e-05])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After decomposition, 'lsa.components_[]' represents matrix V'\n",
    "lsa.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2 |Anaconda 4.2.0 (x86_64)| (default, Jul  2 2016, 17:52:12) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print (sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept 0:\n",
      "priest priest\n",
      "four years\n",
      "immaculate conception\n",
      "answer priest\n",
      "told priest\n",
      "years old\n",
      "case doctrine\n",
      "apparition deemed\n",
      "apparition deemed true\n",
      "apparition deemed true sealed\n",
      " \n",
      "Concept 1:\n",
      "secretary interior\n",
      "married god\n",
      "god eyes\n",
      "appointee james\n",
      "appointee james watt\n",
      "appointee james watt pentacostal\n",
      "christian think\n",
      "christian think secretary\n",
      "christian think secretary interior\n",
      "days would last\n",
      " \n",
      "Concept 2:\n",
      "grass valley\n",
      "daily verse grass\n",
      "daily verse grass valley\n",
      "verse grass\n",
      "verse grass valley\n",
      "verse grass valley grass\n",
      "grass valley grass\n",
      "grass valley grass valley\n",
      "valley grass\n",
      "valley grass valley\n",
      " \n",
      "Concept 3:\n",
      "married god\n",
      "god eyes\n",
      "married god eyes\n",
      "two people\n",
      "people married god\n",
      "two people married god\n",
      "people married\n",
      "two people married\n",
      "become married god\n",
      "become married god eyes\n",
      " \n",
      "Concept 4:\n",
      "eternal death\n",
      "hate sin\n",
      "original sin\n",
      "christians hell\n",
      "atheists hell\n",
      "commands us\n",
      "atheists believe\n",
      "since bible\n",
      "bible problem\n",
      "bible problem view\n",
      " \n",
      "Concept 5:\n",
      "hate sin\n",
      "commands us\n",
      "love sinner\n",
      "sin love\n",
      "hate sin love\n",
      "hate sin love sinner\n",
      "sin love sinner\n",
      "deal sin\n",
      "consistent christianity\n",
      "christianity would think\n",
      " \n",
      "Concept 6:\n",
      "christianity compatible\n",
      "christianity compatible check\n",
      "compatible check\n",
      "issues christianity\n",
      "homosexuality issues\n",
      "homosexuality issues christianity\n",
      "gay christians\n",
      "18 22\n",
      "research center\n",
      "lev 18 22\n",
      " \n",
      "Concept 7:\n",
      "original sin\n",
      "normal humanity\n",
      "doctrine original\n",
      "doctrine original sin\n",
      "god shaped\n",
      "spiritual needs\n",
      "northern research\n",
      "god shaped hole\n",
      "shaped hole\n",
      "mary assumption\n",
      " \n",
      "Concept 8:\n",
      "original sin\n",
      "doctrine original\n",
      "doctrine original sin\n",
      "one enter\n",
      "born water\n",
      "born water spirit\n",
      "water spirit\n",
      "capable comprehending\n",
      "babies supposed\n",
      "babies supposed baptised\n",
      " \n",
      "Concept 9:\n",
      "absolute truth\n",
      "scripture truths\n",
      "truths absolutes\n",
      "absolutes answer\n",
      "truths absolutes answer\n",
      "absolutes scripture\n",
      "always true\n",
      "contradiction terms\n",
      "truth absolute\n",
      "arrogance christians\n",
      " \n",
      "Concept 10:\n",
      "cultural interference\n",
      "ideological manipulation\n",
      "ideological manipulation cultural\n",
      "ideological manipulation cultural interference\n",
      "manipulation cultural\n",
      "manipulation cultural interference\n",
      "phone translators\n",
      "concerned recent\n",
      "concerned recent sil\n",
      "concerned recent sil thought\n",
      " \n",
      "Concept 11:\n",
      "body jesus\n",
      "jewish roman\n",
      "body stolen\n",
      "authorities would gained\n",
      "authorities would gained lot\n",
      "body jesus even\n",
      "body jesus even though\n",
      "dead body jesus\n",
      "dead body jesus even\n",
      "discredited christians\n",
      " \n",
      "Concept 12:\n",
      "normal humanity\n",
      "mary assumption\n",
      "11 51\n",
      "luke 11\n",
      "luke 11 51\n",
      "beyond sanctification\n",
      "beyond sanctification normal\n",
      "beyond sanctification normal humanity\n",
      "greeted mary\n",
      "mary beyond\n",
      " \n",
      "Concept 13:\n",
      "normal humanity\n",
      "mary assumption\n",
      "beyond sanctification\n",
      "beyond sanctification normal\n",
      "beyond sanctification normal humanity\n",
      "greeted mary\n",
      "mary beyond\n",
      "places mary\n",
      "places mary beyond\n",
      "sanctification normal\n",
      " \n",
      "Concept 14:\n",
      "kicked heaven\n",
      "heaven biblical\n",
      "kicked heaven biblical\n",
      "satan kicked\n",
      "satan kicked heaven\n",
      "satan kicked heaven biblical\n",
      "god authority\n",
      "ago satan\n",
      "ago satan angel\n",
      "ago satan angel god\n",
      " \n",
      "Concept 15:\n",
      "saved faith\n",
      "lukewarm christian\n",
      "god shaped\n",
      "god shaped hole\n",
      "shaped hole\n",
      "faith alone\n",
      "faith without\n",
      "say faith\n",
      "faith deeds\n",
      "faith without deeds\n",
      " \n",
      "Concept 16:\n",
      "saved faith\n",
      "lukewarm christian\n",
      "never committed\n",
      "sin whole\n",
      "sin whole life\n",
      "faith alone\n",
      "say faith\n",
      "faith without\n",
      "whole life\n",
      "faith deeds\n",
      " \n",
      "Concept 17:\n",
      "murphy law\n",
      "according purpose\n",
      "according purpose murphy\n",
      "according purpose murphy law\n",
      "amplifications murphy\n",
      "amplifications murphy law\n",
      "amplifications murphy law harmonize\n",
      "anything go\n",
      "anything go wrong\n",
      "anything go wrong familiar\n",
      " \n",
      "Concept 18:\n",
      "knows everything\n",
      "catholic doctrine predestination\n",
      "god knows everything\n",
      "god knows everything knows\n",
      "knows everything knows\n",
      "since god knows\n",
      "since god knows everything\n",
      "doctrine predestination\n",
      "everything knows\n",
      "god judge\n",
      " \n",
      "Concept 19:\n",
      "knows everything\n",
      "catholic doctrine predestination\n",
      "god knows everything\n",
      "god knows everything knows\n",
      "knows everything knows\n",
      "since god knows\n",
      "since god knows everything\n",
      "doctrine predestination\n",
      "everything knows\n",
      "since god\n",
      " \n",
      "Concept 20:\n",
      "exist must\n",
      "enduring values\n",
      "views christianity\n",
      "assume god\n",
      "universe exist\n",
      "atheist views\n",
      "atheist views christianity\n",
      "atheist views christianity accepting\n",
      "christianity accepting\n",
      "christianity accepting jeesus\n",
      " \n",
      "Concept 21:\n",
      "black sabbath\n",
      "spirit filled\n",
      "congregations christians\n",
      "filled believers\n",
      "spirit filled believers\n",
      "visit congregations\n",
      "visit congregations christians\n",
      "maybe trying\n",
      "drug addicts\n",
      "christians happen\n",
      " \n",
      "Concept 22:\n",
      "black sabbath\n",
      "may wrong\n",
      "hell_2 black\n",
      "hell_2 black sabbath\n",
      "may wrong part\n",
      "may wrong part black\n",
      "part black\n",
      "part black sabbath\n",
      "wrong part\n",
      "wrong part black\n",
      " \n",
      "Concept 23:\n",
      "gifted one\n",
      "black sabbath\n",
      "satanic tounges\n",
      "spirit talking\n",
      "modern day\n",
      "witness real\n",
      "speaking tongues\n",
      "different language\n",
      "angelic tongue\n",
      "babel god\n",
      " \n",
      "Concept 24:\n",
      "knew rules\n",
      "medieval period\n",
      "aquinas day\n",
      "ancient books\n",
      "former atheists\n",
      "10th cent\n",
      "10th cent aquinas\n",
      "10th cent aquinas flourished\n",
      "anxious cases\n",
      "anxious cases doubt\n",
      " \n",
      "Concept 25:\n",
      "original sin\n",
      "enter heaven\n",
      "fair god\n",
      "doctrine original\n",
      "doctrine original sin\n",
      "cannot enter heaven\n",
      "cannot enter\n",
      "doctrine original sin sun\n",
      "geno doctrine\n",
      "geno doctrine original\n",
      " \n",
      "Concept 26:\n",
      "mason beaten\n",
      "parents mason\n",
      "parents mason beaten\n",
      "christian parents\n",
      "fundamentalist christian\n",
      "fundamentalist christian parents\n",
      "strict fundamentalist\n",
      "beaten child\n",
      "beaten face\n",
      "beaten face would\n",
      " \n",
      "Concept 27:\n",
      "research center\n",
      "affirmation mcc\n",
      "affirmation mcc churches\n",
      "affirmation mcc churches meet\n",
      "anyone thinks gay\n",
      "anyone thinks gay christianity\n",
      "check dignity\n",
      "check dignity integrity\n",
      "check dignity integrity light\n",
      "christianity compatible check dignity\n",
      " \n",
      "Concept 28:\n",
      "work god\n",
      "genocide work\n",
      "genocide work god\n",
      "serbian genocide\n",
      "serbian genocide work\n",
      "serbian genocide work god\n",
      "god hmm\n",
      "serbs work\n",
      "serbs work god\n",
      "serbs work god hmm\n",
      " \n",
      "Concept 29:\n",
      "codex bezae\n",
      "english translation\n",
      "acts apostles\n",
      "differences long\n",
      "greek nt\n",
      "long recension\n",
      "readings included\n",
      "vaticanus siniaticus\n",
      "1440 variant\n",
      "1440 variant readings\n",
      " \n",
      "Concept 30:\n",
      "proof resurection\n",
      "christ captialist\n",
      "following christ captialist\n",
      "obedience gensis\n",
      "strict obedience\n",
      "strict obedience gensis\n",
      "following christ\n",
      "accordance allow\n",
      "accordance allow witch\n",
      "accordance allow witch live\n",
      " \n",
      "Concept 31:\n",
      "soc religion\n",
      "south africa\n",
      "active liberals\n",
      "active liberals catholics\n",
      "active liberals catholics new\n",
      "agers athiests\n",
      "agers athiests someone\n",
      "agers athiests someone might\n",
      "apparent primarily\n",
      "apparent primarily active\n",
      " \n",
      "Concept 32:\n",
      "south africa\n",
      "never achieve\n",
      "evidence senses\n",
      "goal never\n",
      "goal never achieve\n",
      "arrogance christians\n",
      "science reason\n",
      "achieve know\n",
      "achieve know saved\n",
      "achieve know saved faith\n",
      " \n",
      "Concept 33:\n",
      "never achieve\n",
      "goal never\n",
      "goal never achieve\n",
      "achieve know\n",
      "achieve know saved\n",
      "achieve know saved faith\n",
      "anything think james\n",
      "anything think james tells\n",
      "anyways christians\n",
      "anyways christians know\n",
      " \n",
      "Concept 34:\n",
      "environmentalism paganism\n",
      "_bashing_ paganism\n",
      "_bashing_ paganism figuring\n",
      "_bashing_ paganism figuring present\n",
      "answer pagans\n",
      "answer pagans lot\n",
      "answer pagans lot right\n",
      "bit less\n",
      "bit less effort\n",
      "bit less effort _bashing_\n",
      " \n",
      "Concept 35:\n",
      "ezekiel 18\n",
      "share guilt\n",
      "virgin mary\n",
      "south africa\n",
      "parents responsible\n",
      "teach children\n",
      "68 25\n",
      "let look\n",
      "death came\n",
      "baptism requires\n",
      " \n",
      "Concept 36:\n",
      "enter heaven\n",
      "ezekiel 18\n",
      "cannot enter heaven\n",
      "cannot enter\n",
      "share guilt\n",
      "jesus come\n",
      "sanctifying grace\n",
      "asking jesus\n",
      "asking jesus come\n",
      "asking jesus come heart\n",
      " \n",
      "Concept 37:\n",
      "south africa\n",
      "enter heaven\n",
      "cannot enter heaven\n",
      "virgin mary\n",
      "cannot enter\n",
      "jesus come\n",
      "asking jesus\n",
      "asking jesus come\n",
      "asking jesus come heart\n",
      "come heart\n",
      " \n",
      "Concept 38:\n",
      "christian practices\n",
      "parallel mormon\n",
      "mormon ceremonies\n",
      "mormon temples\n",
      "practices parallel\n",
      "early christian\n",
      "christian worship\n",
      "aspect christian\n",
      "aspect christian worship\n",
      "aspect christian worship involve\n",
      " \n",
      "Concept 39:\n",
      "virgin mary\n",
      "question virgin\n",
      "question virgin mary\n",
      "christian practices\n",
      "parallel mormon\n",
      "mormon ceremonies\n",
      "although bodily\n",
      "although bodily assumption\n",
      "although bodily assumption basis\n",
      "assumption basis\n",
      " \n",
      "Concept 40:\n",
      "become atheists\n",
      "people become\n",
      "people become atheists\n",
      "believe god\n",
      "atheist prayer\n",
      "proven wrong\n",
      "maxwell muir\n",
      "michigan hospitals\n",
      "maxwell muir writes\n",
      "muir writes\n",
      " \n",
      "Concept 41:\n",
      "darin johnson\n",
      "sex christianity\n",
      "gay christians\n",
      "churches remind\n",
      "gay churches\n",
      "gay churches remind\n",
      "christians sex\n",
      "christians sex christianity\n",
      "abstain time\n",
      "abstain time would\n",
      " \n",
      "Concept 42:\n",
      "new christian\n",
      "like ask\n",
      "would like ask\n",
      "israeli government\n",
      "questions new\n",
      "questions new christian\n",
      "steven hoskins\n",
      "although israeli\n",
      "although israeli government\n",
      "although israeli government give\n",
      " \n",
      "Concept 43:\n",
      "revealed truth\n",
      "question authority\n",
      "blind faith\n",
      "evidence may find\n",
      "evidence may find contrary\n",
      "may find contrary\n",
      "regardless evidence\n",
      "regardless evidence may\n",
      "regardless evidence may find\n",
      "find contrary\n",
      " \n",
      "Concept 44:\n",
      "israeli government\n",
      "although israeli\n",
      "although israeli government\n",
      "although israeli government give\n",
      "appears nothing\n",
      "appears nothing stands\n",
      "appears nothing stands way\n",
      "brothers sisters time\n",
      "brothers sisters time hand\n",
      "days although\n",
      " \n",
      "Concept 45:\n",
      "luke account\n",
      "new christian\n",
      "like ask\n",
      "would like ask\n",
      "jewish proselytism\n",
      "cell church\n",
      "questions would\n",
      "would like\n",
      "questions new\n",
      "questions new christian\n",
      " \n",
      "Concept 46:\n",
      "luke account\n",
      "cell church\n",
      "resurrection one\n",
      "believing resurrection\n",
      "christian ever\n",
      "christian trait\n",
      "temper christian\n",
      "temper christian trait\n",
      "death penalty\n",
      "foolish foolish\n",
      " \n",
      "Concept 47:\n",
      "christian trait\n",
      "temper christian\n",
      "temper christian trait\n",
      "foolish foolish\n",
      "losing temper\n",
      "losing temper christian\n",
      "losing temper christian trait\n",
      "acrid angry\n",
      "acrid angry sarcastic\n",
      "angry sarcastic\n",
      " \n",
      "Concept 48:\n",
      "death penalty\n",
      "capital punishment\n",
      "keep peace\n",
      "death penalty revenge\n",
      "penalty revenge\n",
      "try refute\n",
      "catholic liturgy\n",
      "non violent\n",
      "non violent provisions\n",
      "violent provisions\n",
      " \n",
      "Concept 49:\n",
      "virgin mary\n",
      "biblical support\n",
      "homosexual intercourse\n",
      "catholic doctrine\n",
      "revealed church\n",
      "1950 though\n",
      "1950 though certainly\n",
      "1950 though certainly believed\n",
      "assumed body\n",
      "assumed body soul\n",
      " \n",
      "Concept 50:\n",
      "god one set\n",
      "god one set rules\n",
      "one set\n",
      "one set rules\n",
      "set rules\n",
      "ceremonial moral\n",
      "god one\n",
      "ceremonial moral laws\n",
      "ceremonial moral laws one\n",
      "combine ceremonial\n",
      " \n",
      "Concept 51:\n",
      "catholic liturgy\n",
      "palm sunday\n",
      "new things\n",
      "god one set\n",
      "god one set rules\n",
      "one set\n",
      "one set rules\n",
      "set rules\n",
      "quality catholic\n",
      "quality catholic liturgy\n",
      " \n",
      "Concept 52:\n",
      "capital punishment\n",
      "god one set\n",
      "god one set rules\n",
      "one set\n",
      "one set rules\n",
      "set rules\n",
      "ceremonial moral\n",
      "god one\n",
      "homosexual intercourse\n",
      "new testament\n",
      " \n",
      "Concept 53:\n",
      "eternal marriage\n",
      "given marriage\n",
      "marry given\n",
      "marry given marriage\n",
      "neither marry\n",
      "spiritual needs\n",
      "neither marry given\n",
      "neither marry given marriage\n",
      "david hammerslag\n",
      "given marriage luke\n",
      " \n",
      "Concept 54:\n",
      "pa ques\n",
      "cell church\n",
      "new testament\n",
      "especially christianity\n",
      "answer question\n",
      "easter name\n",
      "easter name new\n",
      "easter name new testament\n",
      "name new testament\n",
      "name new testament double\n",
      " \n",
      "Concept 55:\n",
      "eternal marriage\n",
      "given marriage\n",
      "marry given\n",
      "marry given marriage\n",
      "neither marry\n",
      "spiritual needs\n",
      "others danger\n",
      "warning others\n",
      "warning others danger\n",
      "although bodily\n",
      " \n",
      "Concept 56:\n",
      "dreams oobes\n",
      "cell church\n",
      "body incidents\n",
      "dreams body\n",
      "dreams body incidents\n",
      "different moral\n",
      "ethics apply\n",
      "morally responsible\n",
      "david goggin\n",
      "morality applies\n",
      " \n",
      "Concept 57:\n",
      "spiritual needs\n",
      "northern research\n",
      "12 step\n",
      "pa ques\n",
      "recovery programs\n",
      "busy opinion\n",
      "busy opinion opinions\n",
      "busy opinion opinions oh\n",
      "canada philosophies\n",
      "canada philosophies creeds\n",
      " \n",
      "Concept 58:\n",
      "cell church\n",
      "dreams oobes\n",
      "pa ques\n",
      "body incidents\n",
      "dreams body\n",
      "dreams body incidents\n",
      "children born\n",
      "cell church discussion\n",
      "church discussion\n",
      "born wedlock\n",
      " \n",
      "Concept 59:\n",
      "put hell\n",
      "21 27\n",
      "capital punishment\n",
      "21 27 babies\n",
      "21 27 babies born\n",
      "27 babies\n",
      "27 babies born\n",
      "27 babies born state\n",
      "babies born state\n",
      "babies born state die\n",
      " \n",
      "Concept 60:\n",
      "capital punishment\n",
      "brain washed\n",
      "indoctrinated parents\n",
      "become christian\n",
      "believe predestination\n",
      "become christian indoctrinated\n",
      "become christian indoctrinated parents\n",
      "christian indoctrinated\n",
      "christian indoctrinated parents\n",
      "christian indoctrinated parents probably\n",
      " \n",
      "Concept 61:\n",
      "dreams oobes\n",
      "body incidents\n",
      "dreams body\n",
      "dreams body incidents\n",
      "become atheists\n",
      "ethics apply\n",
      "could choose\n",
      "different moral\n",
      "morally responsible\n",
      "born necessity\n",
      " \n",
      "Concept 62:\n",
      "second coming\n",
      "definition religion\n",
      "legal definition\n",
      "legal definition religion\n",
      "pa ques\n",
      "easter name\n",
      "easter name new\n",
      "easter name new testament\n",
      "name new testament\n",
      "name new testament double\n",
      " \n",
      "Concept 63:\n",
      "god shaped\n",
      "brain washed\n",
      "indoctrinated parents\n",
      "become christian\n",
      "become christian indoctrinated\n",
      "become christian indoctrinated parents\n",
      "christian indoctrinated\n",
      "christian indoctrinated parents\n",
      "christian indoctrinated parents probably\n",
      "claim brain\n",
      " \n",
      "Concept 64:\n",
      "repeated lives\n",
      "john baptist\n",
      "cell church\n",
      "elijah come\n",
      "christianity repeated\n",
      "christianity repeated lives\n",
      "capital punishment\n",
      "apostles ask\n",
      "apostles ask pharisees\n",
      "apostles ask pharisees say\n",
      " \n",
      "Concept 65:\n",
      "much later\n",
      "david wagner\n",
      "pregnancy rates\n",
      "church added\n",
      "sex education\n",
      "deutero canonical\n",
      "spiritual quality\n",
      "canonical books\n",
      "abstinence education\n",
      "books added\n",
      " \n",
      "Concept 66:\n",
      "coptic church\n",
      "nabil ayoub\n",
      "oriental orthodox\n",
      "church believe\n",
      "monophysites mike\n",
      "monophysites mike walker\n",
      "wisconsin madison\n",
      "mike walker\n",
      "human nature\n",
      "coptic orthodox church\n",
      " \n",
      "Concept 67:\n",
      "second coming\n",
      "definition religion\n",
      "legal definition\n",
      "legal definition religion\n",
      "mark 13\n",
      "david koresh\n",
      "david koresh second\n",
      "david koresh second coming\n",
      "koresh second\n",
      "koresh second coming\n",
      " \n",
      "Concept 68:\n",
      "cell church\n",
      "gifted one\n",
      "cell church discussion\n",
      "church discussion\n",
      "god shaped\n",
      "glorifying god\n",
      "several people\n",
      "believe gifted\n",
      "believe gifted ones\n",
      "believe gifted ones glorifying\n",
      " \n",
      "Concept 69:\n",
      "much deleted\n",
      "michigan hospitals\n",
      "many people\n",
      "branch davidians\n",
      "true religion\n",
      "paul conditt\n",
      "existed prior\n",
      "meaning importance\n",
      "leopard skin\n",
      "broken ness\n",
      " \n",
      "Concept 70:\n",
      "second coming\n",
      "wife husband\n",
      "husband wife\n",
      "mark 13\n",
      "physical body\n",
      "meaning importance\n",
      "prayers hindered\n",
      "sin block\n",
      "block prayers\n",
      "sin block prayers\n",
      " \n",
      "Concept 71:\n",
      "god shaped\n",
      "god shaped hole\n",
      "shaped hole\n",
      "second coming\n",
      "michael siemon\n",
      "traditional proofs\n",
      "god exists\n",
      "authority truth\n",
      "existence proven\n",
      "existence proven reason\n",
      " \n",
      "Concept 72:\n",
      "certain without\n",
      "shadow doubt\n",
      "jewish proselytism\n",
      "sayeth lord\n",
      "thus sayeth\n",
      "thus sayeth lord\n",
      "every language\n",
      "god shaped\n",
      "remain christian\n",
      "would remain\n",
      " \n",
      "Concept 73:\n",
      "cell church\n",
      "cell church discussion\n",
      "church discussion\n",
      "cell churches\n",
      "death penalty revenge\n",
      "penalty revenge\n",
      "try refute\n",
      "much deleted\n",
      "16 peter\n",
      "16 peter warns\n",
      " \n",
      "Concept 74:\n",
      "jewish proselytism\n",
      "catholic church\n",
      "us ability\n",
      "accounts jewish\n",
      "accounts jewish proselytism\n",
      "accounts jewish proselytism new\n",
      "claim jews\n",
      "claim jews evangelistic\n",
      "claim jews evangelistic except\n",
      "disagree claim\n",
      " \n",
      "Concept 75:\n",
      "definition religion\n",
      "legal definition\n",
      "legal definition religion\n",
      "genesis 15\n",
      "immaculate conception\n",
      "cell church\n",
      "bruise heel\n",
      "crush head\n",
      "crush head bruise\n",
      "crush head bruise heel\n",
      " \n",
      "Concept 76:\n",
      "definition religion\n",
      "legal definition\n",
      "legal definition religion\n",
      "cell church\n",
      "expression mercy\n",
      "supreme court\n",
      "able find\n",
      "able find source\n",
      "able find source even\n",
      "agony one\n",
      " \n",
      "Concept 77:\n",
      "expression mercy\n",
      "blood transfusion\n",
      "michigan hospitals\n",
      "jewish proselytism\n",
      "pregnancy rates\n",
      "baritone range\n",
      "baritone range jesus\n",
      "baritone range jesus chants\n",
      "bass others\n",
      "bass others directly\n",
      " \n",
      "Concept 78:\n",
      "online bible\n",
      "definition religion\n",
      "legal definition\n",
      "legal definition religion\n",
      "never heard\n",
      "would like\n",
      "god shaped\n",
      "natural disaster\n",
      "bible software\n",
      "online bible software\n",
      " \n",
      "Concept 79:\n",
      "god shaped\n",
      "holy spirit\n",
      "god shaped hole\n",
      "shaped hole\n",
      "major views\n",
      "major views trinity\n",
      "views trinity\n",
      "father son\n",
      "14 19\n",
      "exist three\n",
      " \n",
      "Concept 80:\n",
      "spiritual needs\n",
      "definition religion\n",
      "legal definition\n",
      "legal definition religion\n",
      "paul conditt\n",
      "new testament\n",
      "12 step\n",
      "south africa\n",
      "recovery programs\n",
      "jewish proselytism\n",
      " \n",
      "Concept 81:\n",
      "second coming\n",
      "physical body\n",
      "war hell\n",
      "definition religion\n",
      "legal definition\n",
      "legal definition religion\n",
      "rich man\n",
      "cell church\n",
      "mark 13\n",
      "question authority\n",
      " \n",
      "Concept 82:\n",
      "every language\n",
      "bible available\n",
      "every language missionaries\n",
      "language missionaries\n",
      "nearly every language\n",
      "nearly every language missionaries\n",
      "definition religion\n",
      "legal definition\n",
      "legal definition religion\n",
      "michigan hospitals\n",
      " \n",
      "Concept 83:\n",
      "cell church\n",
      "sheila patterson\n",
      "definition christianity\n",
      "certain without\n",
      "shadow doubt\n",
      "sayeth lord\n",
      "thus sayeth\n",
      "thus sayeth lord\n",
      "mr stowell\n",
      "belief jesus\n",
      " \n",
      "Concept 84:\n",
      "god shaped\n",
      "god shaped vacuum\n",
      "shaped vacuum\n",
      "god shaped hole\n",
      "shaped hole\n",
      "something effect\n",
      "would disappear\n",
      "computing science\n",
      "computing science dept\n",
      "glasgow computing\n",
      " \n",
      "Concept 85:\n",
      "god shaped\n",
      "natural disaster\n",
      "every language\n",
      "god shaped hole\n",
      "shaped hole\n",
      "disaster judgement\n",
      "natural disaster judgement\n",
      "bible available\n",
      "question authority\n",
      "second coming\n",
      " \n",
      "Concept 86:\n",
      "cell church\n",
      "remain christian\n",
      "would remain\n",
      "would remain christian\n",
      "catechumens dismissed\n",
      "eucharist secret\n",
      "hank hanegraaff\n",
      "psi writes\n",
      "shellgate uu4\n",
      "shellgate uu4 psi\n",
      " \n",
      "Concept 87:\n",
      "war hell\n",
      "spiritual needs\n",
      "evangelical fundamentalists\n",
      "wear black\n",
      "wear black leather\n",
      "wear black leather jacket\n",
      "goes show\n",
      "black leather\n",
      "black leather jacket\n",
      "leather jacket\n",
      " \n",
      "Concept 88:\n",
      "online bible\n",
      "never heard\n",
      "bible software\n",
      "online bible software\n",
      "people new\n",
      "people new testament\n",
      "question god\n",
      "reference bible\n",
      "scofield reference\n",
      "scofield reference bible\n",
      " \n",
      "Concept 89:\n",
      "people aids\n",
      "christian practices\n",
      "parallel mormon\n",
      "full grace\n",
      "mormon ceremonies\n",
      "austin texas\n",
      "ttt ttt\n",
      "god love\n",
      "genesis 15\n",
      "practices parallel\n",
      " \n",
      "Concept 90:\n",
      "definition religion\n",
      "legal definition\n",
      "legal definition religion\n",
      "free decide\n",
      "better get\n",
      "better get wisdom\n",
      "better get wisdom gold\n",
      "choose understanding\n",
      "choose understanding rather\n",
      "choose understanding rather silver\n",
      " \n",
      "Concept 91:\n",
      "online bible\n",
      "jewish proselytism\n",
      "immaculate conception\n",
      "never heard\n",
      "peter 20\n",
      "empty tomb\n",
      "believe going\n",
      "peter 20 21\n",
      "timothy 16 17\n",
      "bible software\n",
      " \n",
      "Concept 92:\n",
      "definition christianity\n",
      "natural disaster\n",
      "belief jesus\n",
      "definition religion\n",
      "legal definition\n",
      "legal definition religion\n",
      "disaster judgement\n",
      "natural disaster judgement\n",
      "evangelical fundamentalists\n",
      "wear black\n",
      " \n",
      "Concept 93:\n",
      "16 peter\n",
      "16 peter warns\n",
      "16 peter warns scriptures\n",
      "also read peter\n",
      "also read peter 16\n",
      "hard understand learned\n",
      "often hard understand\n",
      "often hard understand learned\n",
      "peter 16\n",
      "peter 16 peter\n",
      " \n",
      "Concept 94:\n",
      "resurrection sunday\n",
      "pagan goddess\n",
      "ted kalivoda\n",
      "private interpretation\n",
      "christian practices\n",
      "parallel mormon\n",
      "far know\n",
      "free decide\n",
      "true heaven\n",
      "argument would compelling\n",
      " \n",
      "Concept 95:\n",
      "holy spirit\n",
      "father son\n",
      "son holy\n",
      "private revelation\n",
      "son holy spirit\n",
      "father son holy\n",
      "father son holy spirit\n",
      "resurrection sunday\n",
      "immaculate conception\n",
      "pagan goddess\n",
      " \n",
      "Concept 96:\n",
      "online bible\n",
      "definition religion\n",
      "legal definition\n",
      "legal definition religion\n",
      "war hell\n",
      "free decide\n",
      "holy spirit\n",
      "never heard\n",
      "jesus christ\n",
      "belief jesus\n",
      " \n",
      "Concept 97:\n",
      "human nature\n",
      "natural disaster\n",
      "cell church\n",
      "god son\n",
      "definition christianity\n",
      "ted kalivoda\n",
      "jesus christ\n",
      "two minds\n",
      "jesus human\n",
      "disaster judgement\n",
      " \n",
      "Concept 98:\n",
      "dead sea\n",
      "dead sea scrolls\n",
      "sea scrolls\n",
      "online bible\n",
      "cell church\n",
      "never heard\n",
      "orthodox churches\n",
      "every language\n",
      "new testament\n",
      "resurrection sunday\n",
      " \n",
      "Concept 99:\n",
      "war hell\n",
      "south africa\n",
      "dead sea scrolls\n",
      "sea scrolls\n",
      "dead sea\n",
      "better war\n",
      "better war hell\n",
      "better war hell war\n",
      "computer science lab\n",
      "computer science lab sri\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Convert the SVD results from numerical representation, back to their appropriate word text form.\n",
    "# Iterates over the enumeration of matrix components, for each: zips the terms to components, sorts them, then prints. \n",
    "terms = vectorizer.get_feature_names()\n",
    "for i, comp in enumerate(lsa.components_): \n",
    "    termsInComp = zip (terms,comp)\n",
    "    sortedTerms =  sorted(termsInComp, key=lambda x: x[1], reverse=True) [:10]\n",
    "    print(\"Concept %d:\" % i )\n",
    "    for term in sortedTerms:\n",
    "        print(term[0])\n",
    "    print (\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Results: Interpration Of Extracted Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**  \n",
    "In order to produce the above output, it took several attempts of fine-tuning the stopset list, vectorization parameters, and SVD parameters then re-running the model. During this process I found that stopset word selection can be tricky, because only those terms which repeat the most across the entire corpus should be excluded. If one unknowingly removes a term which is sparsely found in the corpus, then the efficiency of the model is reduced negatively, impacting both performance and the output of concepts. \n",
    "\n",
    "After trying a handful of different variations, I found the following parameters produce the most meaningful extraction of concepts:  \n",
    "- TfidfVectorizer(stop_words=stopset,use_idf=True, **ngram_range=(2, 4**)\n",
    "- TruncatedSVD(n_components=100, **n_iter=5**)\n",
    "\n",
    "Other configurations tested include ngram_range(1,3), (2,2), (2,3), (2,5), (3,3), and (1,4). For ngrams < 2 the results lacked substance and returned only very simple concepts such as: God, sin, hate, and love. As ngrams_range was adjusted the resulting concepts became much more intricate and meaningful. I also ran a few different configurations with different values for n_iter (epochs), and noticed that this significantly affected the runtime efficiency of the model for any values ~n_iter > 30. I tested n_iter=100, while it took well over 3 minutes to complete execution, the resulting concepts did not appear to have improved much, if at all. \n",
    "\n",
    "The exclusion words were updated several times as well with each test ran, and mostly what I found was that removing certain terms, about 4-5 at a time, then re-testing the model proved successful in the long-run. Specifically the output concepts were checked for terms which appeared out of place, and just 'odd', and then added to the stopset.\n",
    "\n",
    "An important observation made, was that of certain numbers that repeated as concept output. This was super tricky to filter for, as some were extremely significant actually representing bible verses that fit perfectly to the concept (ex: lev 18 22), while others were junk such as the following three numbers:'706','542','0358', which is actually the telephone number for the A.I. department at Georgia Tech! (_If you see a number produced as part of a concept, Google that number to find the bible verse. It proves to be very significant._)  \n",
    "\n",
    "**Interesting Findings**  \n",
    "Christianity is a topic that I am not personally very familiar with, which is in part why I chose it for this study. I wanted to see if I could extract concepts that were very clear to even an observer who is unknowledgeable on  the topic such as myself. \n",
    "\n",
    "I performed some research on a few of the more interesting concepts and ended up with some pretty awesome discoveries:\n",
    "\n",
    "- Ideological Manipulation ([Wikipedia](https://en.wikipedia.org/wiki/Dominant_ideology)):\n",
    ">  \"Social control exercised and effected by means of the _ideological manipulation_ of aspects of the common culture of a society — religion and politics, culture and economy, etc. — to explain and justify the status quo to the political advantage of the dominant (ruling) class...\"  \n",
    "\n",
    "- James G. Watt ([Wikipedia](https://en.wikipedia.org/wiki/James_G._Watt)):\n",
    "> \"James Gaius Watt (born January 31, 1938) served as U.S. Secretary of the Interior from 1981 to 1983. Often described as \"anti-environmentalist\", he was one of Ronald Reagan's most controversial cabinet appointments.\"\n",
    ">\n",
    "> \"In 1995, Watt was indicted on 25 counts of felony perjury and obstruction of justice by a federal grand jury, accused of making false statements before the grand jury investigating influence peddling at the Department of Housing and Urban Development, which he had lobbied in the 1980s\"\n",
    "\n",
    "- Speaking In Tongues ([Wikipedia](https://en.wikipedia.org/wiki/Glossolalia)):\n",
    "> \"Glossolalia or speaking in tongues, according to linguists, is the fluid vocalizing of speech-like syllables that lack any readily comprehended meaning, in some cases as part of religious practice in which it is believed to be a divine language unknown to the speaker.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
