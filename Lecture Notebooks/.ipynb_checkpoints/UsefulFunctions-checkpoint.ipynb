{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here is a simple function to show descriptive stats on the categorical variables\n",
    "def describe_categorical(X):\n",
    "    \"\"\"\n",
    "    Just like .describe(), but returns the results for\n",
    "    categorical variables only.\n",
    "    \"\"\"\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(X[X.columns[X.dtypes == \"object\"]].describe().to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For a df named 'X', this function will fillna all missing values with the mean across the entire data set.\n",
    "def fix_numerical_missings(numerical_variables):\n",
    "    for var in numerical_variables:\n",
    "        X[var].fillna(X[var].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For a df named 'X', this function will mark all categorical missing values with \"Missing\" across the entire data set.\n",
    "# and also will one hot encode the variables using 'get_dummies'. This function is applied to the entire df 'X'\n",
    "\n",
    "def fix_categorical_missings(categorical_variables):\n",
    "    for variable in categorical_variables:\n",
    "        # Fill missing data with the word \"Missing\"\n",
    "        X[variable].fillna(\"Missing\", inplace=True)\n",
    "        # Create array of dummies\n",
    "        dummies = pd.get_dummies(X[variable], prefix=variable)\n",
    "        # Update X to include dummies and drop the main variable\n",
    "        X = pd.concat([X, dummies], axis=1)\n",
    "        X.drop([variable], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This will clean a categorical, by replacing every variable with only the first letter, or \"None\".\n",
    "# This can be a very useful tactic when applied to variables such as 'cabin' from the Titanic dataset.\n",
    "\n",
    "# Change the Cabin variable to be only the first letter or None\n",
    "\n",
    "def clean_first_letter_only(X, var_name):\n",
    "    try:\n",
    "        return x[0]\n",
    "    except TypeError:\n",
    "        return \"None\"\n",
    "\n",
    "    X[var_name] = X[var_name].apply(clean_first_letter_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function will take a feature name, a string or char to replace, and what to replace it with. Entire column.\n",
    "# Note: this is set with '.astype(float)' , adjust this to match the feature data type.\n",
    "\n",
    "def strip_replacein_feature(var_name, string_to_replace, replace_with_string):\n",
    "    X[var_name] = X[var_name].str.replace(string_to_replace , replace_with_string).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look at all the columns in the dataset\n",
    "def printall(X, max_rows=10):\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(X.to_html(max_rows=max_rows)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def graph_variable_importance(model):\n",
    "    # Simple version that shows all of the variables\n",
    "    feature_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "    feature_importances.sort_values(inplace=True)\n",
    "    feature_importances.plot(kind=\"barh\", figsize=(7,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For a df named 'X', returns a list of only the numerical feature labels.\n",
    "def get_numerical_only():\n",
    "    # numeric variables\n",
    "    numerical_variables = list(X.dtypes[X.dtypes != \"object\"].index)\n",
    "    return numerical_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For a df named 'X', returns a list of only the categorical feature labels.\n",
    "def get_categoricals_only():\n",
    "    categorical_variables = list(X.dtypes[X.dtypes == 'object'].index)\n",
    "    X[categorical_variables].shape\n",
    "    return categorical_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Manual parameter tuning for RandomForestRegressor() -- n_estimators\n",
    "def get_best_njobs():\n",
    "    results = []\n",
    "    n_estimator_options = [30, 50, 100, 200, 500, 1000, 2000]\n",
    "\n",
    "    for trees in n_estimator_options:\n",
    "        model = RandomForestRegressor(trees, oob_score=True, n_jobs=-1, random_state=42)\n",
    "        model.fit(X, y)\n",
    "        print (trees, \"trees\")\n",
    "        roc = roc_auc_score(y, model.oob_prediction_)\n",
    "        print (\"C-stat: \", roc)\n",
    "        results.append(roc)\n",
    "        print (\"\")\n",
    "    \n",
    "    pd.Series(results, n_estimator_options).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Manual parameter tuning for RandomForestRegressor() -- max_features\n",
    "def get_best_max_features():\n",
    "    results = []\n",
    "    max_features_options = [\"auto\", None, \"sqrt\", \"log2\", 0.9, 0.2]\n",
    "\n",
    "    for max_features in max_features_options:\n",
    "        model = RandomForestRegressor(n_estimators=1000, oob_score=True, n_jobs=-1, random_state=42, max_features=max_features)\n",
    "        model.fit(X, y)\n",
    "        print (max_features, \"option\")\n",
    "        roc = roc_auc_score(y, model.oob_prediction_)\n",
    "        print (\"C-stat: \", roc)\n",
    "        results.append(roc)\n",
    "        print (\"\")\n",
    "    \n",
    "    pd.Series(results, max_features_options).plot(kind=\"barh\", xlim=(.85,.88));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Manual parameter tuning for RandomForestRegressor() -- min_samples_leaf\n",
    "def get_best_min_samples_leaf():\n",
    "    results = []\n",
    "    min_samples_leaf_options = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "    for min_samples in min_samples_leaf_options:\n",
    "        model = RandomForestRegressor(n_estimators=1000, \n",
    "                                      oob_score=True, \n",
    "                                      n_jobs=-1, \n",
    "                                      random_state=42, \n",
    "                                      max_features=\"auto\", \n",
    "                                      min_samples_leaf=min_samples)\n",
    "        model.fit(X, y)\n",
    "        print (min_samples, \"min samples\")\n",
    "        roc = roc_auc_score(y, model.oob_prediction_)\n",
    "        print (\"C-stat: \", roc)\n",
    "        results.append(roc)\n",
    "        print (\"\")\n",
    "    \n",
    "    pd.Series(results, min_samples_leaf_options).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A much more complex version of plotting for feature importances, with aggregated view.\n",
    "# Provided by Mike Bernico -- only verified to work with RandomTreeRegressor() models.\n",
    "\n",
    "def graph_feature_importances(model, feature_names, autoscale=True, headroom=0.05, width=10, summarized_columns=None):\n",
    "    \"\"\"\n",
    "    By Mike Bernico\n",
    "    \n",
    "    Graphs the feature importances of a random decision forest using a horizontal bar chart. \n",
    "    Probably works but untested on other sklearn.ensembles.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ensemble = Name of the ensemble whose features you would like graphed.\n",
    "    feature_names = A list of the names of those featurs, displayed on the Y axis.\n",
    "    autoscale = True (Automatically adjust the X axis size to the largest feature +.headroom) / False = scale from 0 to 1\n",
    "    headroom = used with autoscale, .05 default\n",
    "    width=figure width in inches\n",
    "    summarized_columns = a list of column prefixes to summarize on, for dummy variables (e.g. [\"day_\"] would summarize all day_ vars\n",
    "    \"\"\"\n",
    "    \n",
    "    if autoscale:\n",
    "        x_scale = model.feature_importances_.max()+ headroom\n",
    "    else:\n",
    "        x_scale = 1\n",
    "    \n",
    "    feature_dict=dict(zip(feature_names, model.feature_importances_))\n",
    "    \n",
    "    if summarized_columns: \n",
    "        #some dummy columns need to be summarized\n",
    "        for col_name in summarized_columns: \n",
    "            #sum all the features that contain col_name, store in temp sum_value\n",
    "            sum_value = sum(x for i, x in feature_dict.items() if col_name in i )  \n",
    "            \n",
    "            #now remove all keys that are part of col_name\n",
    "            keys_to_remove = [i for i in feature_dict.keys() if col_name in i ]\n",
    "            for i in keys_to_remove:\n",
    "                feature_dict.pop(i)\n",
    "            #lastly, read the summarized field\n",
    "            feature_dict[col_name] = sum_value\n",
    "        \n",
    "    results = pd.Series(feature_dict)\n",
    "    results.sort_values(inplace=True)\n",
    "    results.plot(kind=\"barh\", figsize=(width,len(results)/4), xlim=(0,x_scale))\n",
    "    \n",
    "    graph_feature_importances(model, X.columns, summarized_columns=categorical_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get c-stat for a RandomForestRegressor\n",
    "def get_cstat():\n",
    "    roc = roc_auc_score(y, model.oob_prediction_)\n",
    "    return roc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters to test\n",
    "\n",
    " * ### Parameters that will make your model better\n",
    "  * <b>n_estimators</b>: The number of trees in the forest. Choose as high of a number as your computer can handle.\n",
    "  * <b>max_features</b>: The number of features to consider when looking for the best split. Try [\"auto\", \"None\", \"sqrt\", \"log2\", 0.9, and 0.2]\n",
    "  * <b>min_samples_leaf</b>: The minimum number of samples in newly created leaves.Try [1, 2, 3]. If 3 is the best, try higher numbers such as 1 through 10.\n",
    " * ### Parameters that will make it easier to train your model\n",
    "  * <b>n_jobs</b>: Determines if multiple processors should be used to train and test the model. Always set this to -1 and %%timeit vs. if it is set to 1. It should be much faster (especially when many trees are trained)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Params: list form ['v1','v2','v3'], and contain the possible values of parameters to consider in a grid search\n",
    "# with n_job=-1 (full processing power). This returns the estimator object to be stored in memory. \n",
    "# Ex: estimator = gridSearchRFC(n_estimators_param, max_features_param, min_samples_split_param, min_samples_leaf_param)\n",
    "\n",
    "def gridSearchRFC(n_estimators_param, max_features_param, min_samples_split_param, min_samples_leaf_param):\n",
    "\n",
    "    ### Grid Search\n",
    "    n_estimators = [n_estimators_param]\n",
    "    max_features = [max_features_param]\n",
    "    min_samples_split = [min_samples_split_param]\n",
    "    min_samples_leaf = [min_samples_leaf_param]\n",
    "\n",
    "    rfc = RandomForestClassifier(n_jobs=-1)\n",
    "    \n",
    "    estimator = GridSearchCV(rfc,\n",
    "                             dict(n_estimators=n_estimators,\n",
    "                                  max_features=max_features,\n",
    "                                  min_samples_split=min_samples_split,\n",
    "                                  min_samples_leaf=min_samples_leaf\n",
    "                                  ), cv=None, n_jobs=-1)\n",
    "    estimator.fit(X, y)\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "K-Fold Cross Validation to use on best_rfc model from gridsearch: best_rfc = estimator.best_estimator_\n",
    "Param: Pass this function the number of K-Folds to use, that is how many \"chunks\" to break the data into. \n",
    "If unsure, use K = 10. Function returns the confidence interval at 95% probability.\n",
    "Required import: from sklearn import cross_validation\n",
    "Note: 2.262 = the value for 95% c.i.\n",
    "\n",
    "***********************************************************************************************************************\n",
    "Setup:\n",
    "Prior to run ensure to follow a similar setup as below...\n",
    "\n",
    "Ex prepartion code:\n",
    "\n",
    "data = pd.read_csv(\"somedata.csv\")\n",
    "y = data.pop(\"y_col_name\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=.2, random_state=42)\n",
    "estimator = gridSearchRFC(n_estimators_param, max_features_param, min_samples_split_param, min_samples_leaf_param)\n",
    "best_rfc = estimator.best_estimator_\n",
    "get_kfolds_ci(10)\n",
    "***********************************************************************************************************************\n",
    "'''\n",
    "\n",
    "\n",
    "def get_kfolds_ci(num_k_folds):\n",
    "    scores = cross_validation.cross_val_score(best_rfc, data, y, cv=num_k_folds)\n",
    "    mean_score = scores.mean()\n",
    "    std_dev = scores.std()\n",
    "    std_error = scores.std() / math.sqrt(scores.shape[0])\n",
    "    ci =  2.262 * std_error\n",
    "    lower_bound = mean_score - ci\n",
    "    upper_bound = mean_score + ci\n",
    "\n",
    "    print(\"95% Confidence Interval for K-Folds = \", num_k_folds, \":\")\n",
    "    print (\"Score is %f +/-  %f\" % (mean_score, ci))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
