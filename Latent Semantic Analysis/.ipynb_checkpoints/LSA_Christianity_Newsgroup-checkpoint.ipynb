{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Semantic Analysis:\n",
    "## _Data Mining for Meaningful Concepts In Christianity Newsgroups_\n",
    "---\n",
    "\n",
    "Prepared By: Jason Schenck  \n",
    "Date: February 6th 2017  \n",
    "CSC-570 Data Science Essentials\n",
    "\n",
    "\n",
    "<br>\n",
    "<big>Table Of Contents</big>\n",
    "\n",
    "---\n",
    "* **[1 Introduction][Introduction]**\n",
    "   * [1.1][1.1] _Purpose & Data Source_\n",
    "   * [1.2][1.2] _What is a \"Latent Semantic Analysis\"(LSA)?_\n",
    "   * [1.3][1.3] _Terminology Defined_\n",
    "   * [1.4][1.4] _Process/Procedure & Methodology_\n",
    "\n",
    "\n",
    "* **[2 Data Preparation][Data Preparation]**\n",
    "   * [2.1][2.1] _Data Retrieval_\n",
    "   * [2.2][2.2] _Data Inspection_\n",
    "   * [2.3][2.3] _Defining 'stopwords'_\n",
    "\n",
    "\n",
    "* **[3 Lexical Semantic Analysis (LSA)][Lexical Semantic Analysis (LSA)]**\n",
    "   * [3.1][3.1] _TF-IDF Vectorization_\n",
    "   * [3.2][3.2] _3.2 SVD Modeling with Scikit-Learn_\n",
    "\n",
    "\n",
    "* **[4 Results: Interpration Of Extracted Concepts][Results: Interpration Of Extracted Concepts]**\n",
    "\n",
    "\n",
    "\n",
    "     \n",
    "[Introduction]: #1-Introduction\n",
    "[1.1]: #1.1-Purpose-&-Data-Source\n",
    "[1.2]: #1.2-What-is-a-\"Latent-Semantic-Analysis\"(LSA)?\n",
    "[1.3]: #1.3-Terminology-Defined\n",
    "[1.4]: #1.4-Process/Procedure-&-Methodology\n",
    "[Data Preparation]: #2-Data-Preparation\n",
    "[2.1]: #2.1-Data-Retrieval\n",
    "[2.2]: #2.2-Data-Inspection\n",
    "[2.3]: #2.3-Defining-'stopwords'\n",
    "[Lexical Semantic Analysis (LSA)]: #3-Lexical-Semantic-Analysis-(LSA)\n",
    "[3.1]: #3.1-TF-IDF-Vectorization\n",
    "[3.2]: #3.2-SVD-Modeling-with-Scikit-Learn\n",
    "[Results: Interpration Of Extracted Concepts]: #4-Results:-Interpration-Of-Extracted-Concepts\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>Data Source</b> [\"Twenty Newsgroups\", Provided By: Scikit-Learn](http://scikit-learn.org/stable/datasets/twenty_newsgroups.html#)\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Purpose & Data Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this analysis I will be performing data mining in an effort to extract a series of meaningful and significant concepts from a public dataset of newsgroup postings on the topic of Christianity.\n",
    "\n",
    "The dataset, titled \"Twenty Newsgroups\" and is officially described as follows:\n",
    ">\"The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups. To the best of our knowledge, it was originally collected by Ken Lang, probably for his paper “Newsweeder: Learning to filter netnews,” though he does not explicitly mention this collection. The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.\"\n",
    "\n",
    "A newsgroup is an online public forum for discussion on a particular topic. The topic that I will be extracting data from will be \"Christianity\" (soc.religion.christian). I'm very curious to see what the results of this analysis will be, and in concluding intend to share my opinion on them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 What is a \"Latent Semantic Analysis\"(LSA)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent Semantic Analysis (LSA) is a technique commonly used in the field of Natural Language Processing (NLP). As a computer scientist, when performing NLP we are concerned with studying the interactions and between computers and human language. A great portion of this field focuses on the analysis of the relationship between multiple words in a document of text containing in a collection of documents. This is known as the subfield of Natural Language Understanding and can be thought of more simply as teaching computers how to read. \n",
    "\n",
    "LSA is more formally defined by [\"An Introduction to Latent Semantic Analysis\" by Landauer, Foltz, & Laham](http://lsa.colorado.edu/papers/dp1.LSAintro.pdf)\n",
    ">\"Latent Semantic Analysis (LSA) is a theory and method for extracting and representing the\n",
    "contextual-usage meaning of words by statistical computations applied to a large corpus of\n",
    "text (Landauer and Dumais, 1997). The underlying idea is that the aggregate of all the word\n",
    "contexts in which a given word does and does not appear provides a set of mutual\n",
    "constraints that largely determines the similarity of meaning of words and sets of words to\n",
    "each other.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Terminology Defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a vast list of new terminoloy defined by the field of NLP. Below I will briefly define those of significance to LSA that I will be using regularly throughout this analysis.\n",
    "\n",
    "* **Word** - A single English word in text.\n",
    "* **Bag Of Words (BOW)** - An abstraction model in NLP where we consider each document of text to simply be a \"bag of words\" in the literal sense, such that grammar and conceptual meaning is ignored.\n",
    "* **Term Frequency–Inverse Document Frequency (TF-IDF)** - A mathematical calculation for scoring the importance of a word in a document or a collection. \n",
    "* **Term** - A single word found in a document of text.\n",
    "* **Document** - A single collection of terms.\n",
    "* **Corpus** - A single collection documents.\n",
    "* **Concept** - The final output of and LSA is a list of concepts. These are words, or multiple words together, which were found to have the highest significance across our corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Process/Procedure & Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In brief, I will summarize a list of 7 steps representing the overall process required to perform an LSA:\n",
    "\n",
    "1. Collect/Retrieve a dataset containing text of interest. \n",
    "2. Define which text in the dataset will be represented as documents (sentences, discussion board poasts, news articles, ?)\n",
    "3. Using the BOW model, parse by document and store words in a bag of words where each bag is a document. Ending result should be a collection of documents of tokenized words.\n",
    "4. Clean the data. Remove as many unneccessary words and characters as possible.\n",
    "5. Perform TF-IDF Vectorization. This scores the words as terms for each document and across the document collection as a whole. \n",
    "6. Matrix decomposition using the Singular Value Decomposition algorithm.\n",
    "7. Output a list of concepts extracted. \n",
    "\n",
    "Now we can begin our prepartions for LSA, starting with step 1, importing the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports, and dataset download via sk-learn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import re\n",
    "\n",
    "categories = ['soc.religion.christian']\n",
    "dataset = fetch_20newsgroups(subset='all',shuffle=True, random_state=42, categories=categories)\n",
    "corpus = dataset.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "997"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many documents (forum posts) are in the dataset\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: sciysg@nusunix1.nus.sg (Yung Shing Gene)\\nSubject: Mission Aviation Fellowship\\nOrganization: National University of Singapore\\nLines: 3\\n\\nHi,\\n\\tDoes anyone know anything about this group and what they\\ndo? Any info would be appreciated. Thanks!\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first document\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Print the first 10 documents to inspect the data\\nfor x in range(0,12):\\n    print(corpus[x])\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# * Uncomment to inspect the raw data *\n",
    "\"\"\"\n",
    "# Print the first 10 documents to inspect the data\n",
    "for x in range(0,12):\n",
    "    print(corpus[x])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears our data is in plain text with no tagging. However, each post starts with a heading which I've noticed is also variable across the corpus. For example some posts start with a header containing \"From\", \"Subject\", and \"Organization\" while others do not. The following headers are present across the corpus document:  \n",
    "* **From:** [ _email@emailaddress.com_ ]\n",
    "* **Subject:** [ _topic_ ]\n",
    "* **Reply-To:** [ _email@emailaddress.com_ ]\n",
    "* **Organization:** [ _Organization Name_ ]\n",
    "* **Lines:** [ _# Lines of post_ ]\n",
    "\n",
    "Also, it appears that a post can be from either a public individual or a member of an organization. In either case, posts can be new posts or replies to other's posts. Every header ends with **\"Lines:\"** which tells us the number of lines of text contained in the post message itself.\n",
    "\n",
    "\n",
    "Post content looks like it could be problemsome for LSA if I don't include plenty of words and characters to exclude with the \"stopset\". For example, below is a post that demonstrates what we are dealing with in regard to post content.\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "We are going to want to exclude e-mail addresses and poster's names because these will hinder the performance of our analysis. In the above post, I see that quoted articles may be included as well. Quote blocks appear to contain a brief header, and then are marked with '>' before each line contained in the quote. I plan to leave the articles in the dataset for my first LSA attempt, but I will definitely need to exclude the '>' characters. Also punctuation and capitalization should be taken care of as well. The hardest part will be excluding e-mail addresses and names since they are so variable across the corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from: sciysg@nusunix1.nus.sg (yung shing gene)\\nsubject: mission aviation fellowship\\norganization: national university of singapore\\nlines: 3\\n\\nhi,\\n\\tdoes anyone know anything about this group and what they\\ndo? any info would be appreciated. thanks!\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert all text to lower-case\n",
    "postDocs = [x.lower() for x in corpus]\n",
    "\n",
    "# Check it\n",
    "postDocs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: \\nSubject: tongues (read me!)\\nLines: 8\\n\\nPersons interested in the tongues question are are invited to\\nperuse an essay of mine, obtainable by sending the message\\n GET TONGUES NOTRANS\\n to  or to\\n    \\n\\n Yours,\\n James Kiefer\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using regex, find and remove all e-mail addresses\n",
    "corpus = [re.sub(r'(\\s)(\\S+\\@\\S+)(\\s)', r'\\1\\3', corpus[x]) for x in range(len(corpus))]\n",
    "\n",
    "# Ensure successful\n",
    "corpus[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Defining 'stopwords'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have all of the e-mail addresses stored, as well as a fairly decent idea of what needs to be included, I will build the stopset. \n",
    "\n",
    "A stopset is a list of **'stopwords'** which will be excluded from analysis automatically by scikit-learn's vectorization algorithm. For this LSA, I'm going to use a combination of three lists for the first attempt: a stopset provided by my professor, one that I found online called the _terrier stop-set_, and all of the e-mail addresses of the corpus.\n",
    "\n",
    "In order to do this, I will store Professor Bernico's set manually, then I will import the terrier set, and then finally I will union all three into one set with no duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jasonschenck/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This set was provided to me, and updated by my professor\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# ORIGINAL\n",
    "stopset = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "\n",
    "stopset.update(['nova','gmi','khan0095','budd','28','30602','bud','nj','44','31','10','11','31','wkuvx1',\n",
    "                'bitnet','easteee','holt','gatech','carol','howard','len','hampton','va','cs','terrance',\n",
    "                'watt','apointee','acad1','sahs','uth','randerso','larc','gov','whitesbsd','nextwork','trol',\n",
    "                'eeap','apr','r2d2','vbv','3062','7415','n4tmi','wbt','wycliffe','david','paul','ata','hfsi','uk',\n",
    "                'fidonet','jeff','fenholt','indiana','fisher','microsystems','creps','alvin','netcom','andrew','fil',\n",
    "                'revdak','jr','velasco','virgilio','ac','za','hayesstw','risc1','ucs','lee','nicholas',\n",
    "                'mandock','randal','overacker','larry','bernard','elizabeth','dean','seanna','unisa','rose','bryan',\n",
    "                'bnr','jayne','heath','scott','michael','llo','acs','vela','atterlep','lines',\n",
    "                'petch','carlson','caralv','0358','706','542','subject','university','georgia','aisun3','reply-to',\n",
    "                'organization','hulman','hayes','steve','mcovingt','ai','ca','covington','bigelow','eugene','tek',\n",
    "                'gvg47','chuck','gvg','com','uga','bernadette','rutgers','edu','lt','p','/p','br','amp','quot',\n",
    "                'font','span','0px','rgb','51','spacing','text','helvetica', 'arial','indent','line','none','sans',\n",
    "                'serif','line','title','word','0pt','16','12','14','21', 'neue','johnsd2','rpi','mls','panix','ebay',\n",
    "                'group','aa888','freenet','mark','carleton','ncr','cso','uxa','uiuc','bjorn','elsegundoca',\n",
    "                'mit','koberg','gt7122b','oo','la','microsoft','kuhub','cc','ukans','codex','fnal','marka','csd',\n",
    "                'sapienza','lady', ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's take a look\n",
    "#stopset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TERRIER\n",
    "terrierstopset = open('terrierstopset.txt', 'r').read()\n",
    "stopset = set(stopset).union(set(terrierstopset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nprint(stopset)\\n\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# * Uncomment to review the stopset wordlist *\n",
    "\"\"\"\n",
    "\n",
    "print(stopset)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Lexical Semantic Analysis (LSA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the vectorizer model -- TfidfVectorizer(set stopwords = ?, use idf = true, num grams range = ?)\n",
    "vectorizer = TfidfVectorizer(stop_words=stopset,use_idf=True, ngram_range=(2, 5))\n",
    "\n",
    "# Fit the corpus data to the vectorizer model\n",
    "X = vectorizer.fit_transform(postDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 463220)\t0.122190056616\n",
      "  (0, 365021)\t0.106667010589\n",
      "  (0, 364984)\t0.100966773934\n",
      "  (0, 475177)\t0.122190056616\n",
      "  (0, 591646)\t0.122190056616\n",
      "  (0, 476784)\t0.122190056616\n",
      "  (0, 215969)\t0.122190056616\n",
      "  (0, 342444)\t0.122190056616\n",
      "  (0, 58524)\t0.122190056616\n",
      "  (0, 200883)\t0.122190056616\n",
      "  (0, 352929)\t0.106667010589\n",
      "  (0, 483406)\t0.122190056616\n",
      "  (0, 248261)\t0.11044732561\n",
      "  (0, 41364)\t0.0892240429277\n",
      "  (0, 288806)\t0.103578268315\n",
      "  (0, 41981)\t0.122190056616\n",
      "  (0, 267272)\t0.122190056616\n",
      "  (0, 580547)\t0.106667010589\n",
      "  (0, 45007)\t0.106667010589\n",
      "  (0, 463221)\t0.122190056616\n",
      "  (0, 365022)\t0.106667010589\n",
      "  (0, 365006)\t0.122190056616\n",
      "  (0, 475178)\t0.122190056616\n",
      "  (0, 591647)\t0.122190056616\n",
      "  (0, 476785)\t0.122190056616\n",
      "  :\t:\n",
      "  (0, 58526)\t0.122190056616\n",
      "  (0, 200885)\t0.122190056616\n",
      "  (0, 352943)\t0.122190056616\n",
      "  (0, 483408)\t0.122190056616\n",
      "  (0, 248263)\t0.115320999322\n",
      "  (0, 41369)\t0.122190056616\n",
      "  (0, 288813)\t0.122190056616\n",
      "  (0, 41983)\t0.122190056616\n",
      "  (0, 267274)\t0.122190056616\n",
      "  (0, 463223)\t0.122190056616\n",
      "  (0, 365028)\t0.122190056616\n",
      "  (0, 365008)\t0.122190056616\n",
      "  (0, 475180)\t0.122190056616\n",
      "  (0, 591649)\t0.122190056616\n",
      "  (0, 476787)\t0.122190056616\n",
      "  (0, 215972)\t0.122190056616\n",
      "  (0, 342447)\t0.122190056616\n",
      "  (0, 58527)\t0.122190056616\n",
      "  (0, 200886)\t0.122190056616\n",
      "  (0, 352944)\t0.122190056616\n",
      "  (0, 483409)\t0.122190056616\n",
      "  (0, 248264)\t0.122190056616\n",
      "  (0, 41370)\t0.122190056616\n",
      "  (0, 288814)\t0.122190056616\n",
      "  (0, 41984)\t0.122190056616\n"
     ]
    }
   ],
   "source": [
    "# Tada! This is now the output of the first document in the corpus, in sparse idf matrix form.\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(997, 592004)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The current shape is (documents, terms)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 SVD Modeling with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=100, n_iter=5,\n",
       "       random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Begin by defining the TruncatedSVD model (num rows/docs?, how many passes over the data (epochs)? )\n",
    "#Note: n_iter defaults to 5 if not passed, and 1 if using partial_fit\n",
    "lsa = TruncatedSVD(n_components=100, n_iter=5)\n",
    "\n",
    "# Fit the model\n",
    "lsa.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.36481235e-05,   1.11570008e-04,   1.11570008e-04, ...,\n",
       "         1.42519921e-05,   1.42519921e-05,   1.42519921e-05])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After decomposition, 'lsa.components_[]' represents matrix V'\n",
    "lsa.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2 |Anaconda 4.2.0 (x86_64)| (default, Jul  2 2016, 17:52:12) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print (sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept 0:\n",
      "priest priest\n",
      "four years\n",
      "immaculate conception\n",
      "answer priest\n",
      "told priest\n",
      "years old\n",
      "case doctrine\n",
      "apparition deemed\n",
      "apparition deemed true\n",
      "apparition deemed true sealed\n",
      " \n",
      "Concept 1:\n",
      "secretary interior\n",
      "married god\n",
      "god eyes\n",
      "married god eyes\n",
      "appointee james\n",
      "appointee james pentacostal\n",
      "appointee james pentacostal christian\n",
      "appointee james pentacostal christian think\n",
      "christian think\n",
      "christian think secretary\n",
      " \n",
      "Concept 2:\n",
      "grass valley\n",
      "daily verse grass\n",
      "daily verse grass valley\n",
      "daily verse grass valley grass\n",
      "verse grass\n",
      "verse grass valley\n",
      "verse grass valley grass\n",
      "verse grass valley grass valley\n",
      "grass valley grass\n",
      "grass valley grass valley\n",
      " \n",
      "Concept 3:\n",
      "married god\n",
      "god eyes\n",
      "married god eyes\n",
      "article may\n",
      "original sin\n",
      "issues christianity\n",
      "two people\n",
      "homosexuality issues\n",
      "homosexuality issues christianity\n",
      "christianity compatible\n",
      " \n",
      "Concept 4:\n",
      "married god\n",
      "god eyes\n",
      "married god eyes\n",
      "two people\n",
      "people married god\n",
      "two people married god\n",
      "people married\n",
      "two people married\n",
      "become married god\n",
      "become married god eyes\n",
      " \n",
      "Concept 5:\n",
      "hate sin\n",
      "commands us\n",
      "love sinner\n",
      "sin love\n",
      "hate sin love\n",
      "hate sin love sinner\n",
      "sin love sinner\n",
      "deal sin\n",
      "consistent christianity\n",
      "christianity would think\n",
      " \n",
      "Concept 6:\n",
      "original sin\n",
      "eternal death\n",
      "spiritual needs\n",
      "bell northern\n",
      "bell northern research\n",
      "northern research\n",
      "never committed\n",
      "sin whole\n",
      "sin whole life\n",
      "whole life\n",
      " \n",
      "Concept 7:\n",
      "eternal death\n",
      "christians hell\n",
      "atheists hell\n",
      "bible problem\n",
      "bible problem view\n",
      "bible problem view since\n",
      "bible problem view since bible\n",
      "bible talks fires\n",
      "bible talks fires hell\n",
      "interpreters bible\n",
      " \n",
      "Concept 8:\n",
      "original sin\n",
      "doctrine original\n",
      "doctrine original sin\n",
      "one enter\n",
      "born water\n",
      "born water spirit\n",
      "water spirit\n",
      "capable comprehending\n",
      "babies supposed\n",
      "babies supposed baptised\n",
      " \n",
      "Concept 9:\n",
      "absolute truth\n",
      "scripture truths\n",
      "absolutes answer\n",
      "absolutes scripture\n",
      "always true\n",
      "contradiction terms\n",
      "arrogance christians\n",
      "true obviously\n",
      "scripture absolute\n",
      "trying say\n",
      " \n",
      "Concept 10:\n",
      "body jesus\n",
      "body stolen\n",
      "jewish roman\n",
      "really rise\n",
      "authorities would gained\n",
      "authorities would gained lot\n",
      "authorities would gained lot would\n",
      "body jesus even\n",
      "body jesus even though\n",
      "body jesus even though jewish\n",
      " \n",
      "Concept 11:\n",
      "cultural interference\n",
      "ideological manipulation\n",
      "ideological manipulation cultural\n",
      "ideological manipulation cultural interference\n",
      "manipulation cultural\n",
      "manipulation cultural interference\n",
      "phone number\n",
      "number translators\n",
      "phone number translators\n",
      "concerned recent\n",
      " \n",
      "Concept 12:\n",
      "normal humanity\n",
      "central sun\n",
      "24 well\n",
      "24 well luke\n",
      "24 well luke taking\n",
      "24 well luke taking genesis\n",
      "also noteworthy\n",
      "also noteworthy consider\n",
      "also noteworthy consider jesus\n",
      "also noteworthy consider jesus attitude\n",
      " \n",
      "Concept 13:\n",
      "normal humanity\n",
      "god judge\n",
      "go hell\n",
      "believe christian god\n",
      "go heaven\n",
      "believe christian\n",
      "christian god\n",
      "going hell\n",
      "another effect\n",
      "another effect go\n",
      " \n",
      "Concept 14:\n",
      "god shaped\n",
      "god shaped hole\n",
      "shaped hole\n",
      "accepting jeesus\n",
      "accepting jeesus heart\n",
      "jeesus heart\n",
      "eric molas\n",
      "empty spot\n",
      "empty spot god\n",
      "empty spot god shaped\n",
      " \n",
      "Concept 15:\n",
      "kicked heaven\n",
      "heaven biblical\n",
      "kicked heaven biblical\n",
      "satan kicked\n",
      "satan kicked heaven\n",
      "satan kicked heaven biblical\n",
      "god authority\n",
      "ago satan\n",
      "ago satan really\n",
      "ago satan really angel\n",
      " \n",
      "Concept 16:\n",
      "go hell\n",
      "god judge\n",
      "believe christian god\n",
      "go heaven\n",
      "believe christian\n",
      "christian god\n",
      "another effect\n",
      "another effect go\n",
      "another effect go hell\n",
      "another effect go hell interested\n",
      " \n",
      "Concept 17:\n",
      "saved faith\n",
      "lukewarm christian\n",
      "faith alone\n",
      "faith without\n",
      "battling problem\n",
      "battling problem know\n",
      "battling problem know romans\n",
      "battling problem know romans talks\n",
      "believing enough\n",
      "christian battling\n",
      " \n",
      "Concept 18:\n",
      "murphy law\n",
      "tim rolfe\n",
      "junior dsu\n",
      "rolfe junior\n",
      "rolfe junior dsu\n",
      "according purpose\n",
      "according purpose murphy\n",
      "according purpose murphy law\n",
      "according purpose murphy law anything\n",
      "amplifications commentary\n",
      " \n",
      "Concept 19:\n",
      "mason beaten\n",
      "parents mason\n",
      "parents mason beaten\n",
      "raised oakland\n",
      "christian parents\n",
      "fundamentalist christian\n",
      "fundamentalist christian parents\n",
      "jose mercury\n",
      "jose mercury news\n",
      "mercury news\n",
      " \n",
      "Concept 20:\n",
      "murphy law\n",
      "south africa\n",
      "dps nasa\n",
      "dps nasa kodak\n",
      "nasa kodak\n",
      "spirit filled\n",
      "tim rolfe\n",
      "junior dsu\n",
      "rolfe junior\n",
      "rolfe junior dsu\n",
      " \n",
      "Concept 21:\n",
      "dps nasa\n",
      "dps nasa kodak\n",
      "nasa kodak\n",
      "spirit filled\n",
      "lois christiansen\n",
      "loisc lois\n",
      "loisc lois christiansen\n",
      "congregations christians\n",
      "filled believers\n",
      "spirit filled believers\n",
      " \n",
      "Concept 22:\n",
      "knows everything\n",
      "gifted one\n",
      "catholic doctrine predestination\n",
      "god knows everything\n",
      "since god knows\n",
      "since god knows everything\n",
      "doctrine predestination\n",
      "since god\n",
      "god knows\n",
      "catholic doctrine\n",
      " \n",
      "Concept 23:\n",
      "gifted one\n",
      "ssd harris\n",
      "satanic tounges\n",
      "spirit talking\n",
      "witness real\n",
      "speaking tongues\n",
      "modern day\n",
      "different language\n",
      "colorado allen\n",
      "spot colorado allen\n",
      " \n",
      "Concept 24:\n",
      "exist must\n",
      "enduring values\n",
      "assume god\n",
      "views christianity\n",
      "universe exist\n",
      "atheist views\n",
      "atheist views christianity\n",
      "atheist views christianity accepting\n",
      "atheist views christianity accepting jeesus\n",
      "christianity accepting\n",
      " \n",
      "Concept 25:\n",
      "knew rules\n",
      "medieval period\n",
      "bill mayne\n",
      "aquinas day\n",
      "ancient books\n",
      "josh mcdowell\n",
      "former atheists\n",
      "10th cent\n",
      "10th cent aquinas\n",
      "10th cent aquinas flourished\n",
      " \n",
      "Concept 26:\n",
      "enter heaven\n",
      "shell oil\n",
      "original sin\n",
      "sun geno\n",
      "cannot enter heaven\n",
      "doctrine original\n",
      "doctrine original sin\n",
      "shellgate uu4\n",
      "shellgate uu4 psi\n",
      "uu4 psi\n",
      " \n",
      "Concept 27:\n",
      "enter heaven\n",
      "original sin\n",
      "sun geno\n",
      "doctrine original\n",
      "doctrine original sin\n",
      "cannot enter heaven\n",
      "fair god\n",
      "doctrine original sin reply sun\n",
      "geno doctrine\n",
      "geno doctrine original\n",
      " \n",
      "Concept 28:\n",
      "shell oil\n",
      "midway uchicago\n",
      "noye midway\n",
      "noye midway uchicago\n",
      "ab24 nasa\n",
      "ab24 nasa ann\n",
      "nasa ann\n",
      "langley research\n",
      "langley research center\n",
      "nasa langley\n",
      " \n",
      "Concept 29:\n",
      "black sabbath\n",
      "may wrong\n",
      "hell_2 black\n",
      "hell_2 black sabbath\n",
      "jprzybyl skidmore\n",
      "may wrong part\n",
      "may wrong part black\n",
      "may wrong part black sabbath\n",
      "part black\n",
      "part black sabbath\n",
      " \n",
      "Concept 30:\n",
      "jcj tellabs\n",
      "cgsvax claremont\n",
      "reedr cgsvax\n",
      "reedr cgsvax claremont\n",
      "proof resurection\n",
      "jcj tellabs jcj\n",
      "tellabs jcj\n",
      "christ captialist\n",
      "following christ captialist\n",
      "obedience gensis\n",
      " \n",
      "Concept 31:\n",
      "english translation\n",
      "acts apostles\n",
      "become atheists\n",
      "people become\n",
      "people become atheists\n",
      "differences long\n",
      "greek nt\n",
      "long recension\n",
      "readings included\n",
      "vaticanus siniaticus\n",
      " \n",
      "Concept 32:\n",
      "stan armstrong\n",
      "never achieve\n",
      "goal never\n",
      "goal never achieve\n",
      "achieve know\n",
      "achieve know saved\n",
      "achieve know saved faith\n",
      "achieve know saved faith works\n",
      "anything think james\n",
      "anything think james tells\n",
      " \n",
      "Concept 33:\n",
      "english translation\n",
      "acts apostles\n",
      "shell oil\n",
      "differences long\n",
      "greek nt\n",
      "long recension\n",
      "readings included\n",
      "vaticanus siniaticus\n",
      "knows everything\n",
      "shellgate uu4\n",
      " \n",
      "Concept 34:\n",
      "evidence senses\n",
      "science reason\n",
      "prove anything\n",
      "arrogance christians\n",
      "physical sphere\n",
      "work god\n",
      "stan armstrong\n",
      "ask question\n",
      "phs431d vaxc\n",
      "phs431d vaxc monash\n",
      " \n",
      "Concept 35:\n",
      "work god\n",
      "james sledd\n",
      "soc religion\n",
      "genocide work\n",
      "genocide work god\n",
      "serbian genocide\n",
      "serbian genocide work\n",
      "serbian genocide work god\n",
      "ssdc sas\n",
      "god hmm\n",
      " \n",
      "Concept 36:\n",
      "soc religion\n",
      "active liberals\n",
      "active liberals catholics\n",
      "active liberals catholics new\n",
      "active liberals catholics new agers\n",
      "agers athiests\n",
      "agers athiests someone\n",
      "agers athiests someone might\n",
      "agers athiests someone might think\n",
      "anni dozier\n",
      " \n",
      "Concept 37:\n",
      "environmentalism paganism\n",
      "_bashing_ paganism\n",
      "_bashing_ paganism figuring\n",
      "_bashing_ paganism figuring present\n",
      "_bashing_ paganism figuring present gospel\n",
      "answer pagans\n",
      "answer pagans lot\n",
      "answer pagans lot right\n",
      "answer pagans lot right questions\n",
      "bit less\n",
      " \n",
      "Concept 38:\n",
      "enter heaven\n",
      "revealed truth\n",
      "question authority\n",
      "cannot enter heaven\n",
      "andy bgsu pixie\n",
      "bgsu pixie\n",
      "dleonar andy\n",
      "dleonar andy bgsu\n",
      "dleonar andy bgsu pixie\n",
      "cannot enter\n",
      " \n",
      "Concept 39:\n",
      "enter heaven\n",
      "cannot enter heaven\n",
      "cannot enter\n",
      "jesus come\n",
      "asking jesus\n",
      "asking jesus come\n",
      "asking jesus come heart\n",
      "come heart\n",
      "jesus come heart\n",
      "luke account\n",
      " \n",
      "Concept 40:\n",
      "ezekiel 18\n",
      "noye midway\n",
      "noye midway uchicago\n",
      "midway uchicago\n",
      "share guilt\n",
      "parents responsible\n",
      "virgin mary\n",
      "teach children\n",
      "aaron bryce\n",
      "aaron bryce cardenas\n",
      " \n",
      "Concept 41:\n",
      "eng sun\n",
      "luke account\n",
      "gchin ssf\n",
      "gchin ssf eng\n",
      "gchin ssf eng sun\n",
      "ssf eng\n",
      "ssf eng sun\n",
      "gary chin\n",
      "703 827\n",
      "really rise\n",
      " \n",
      "Concept 42:\n",
      "noye midway\n",
      "noye midway uchicago\n",
      "midway uchicago\n",
      "source existence\n",
      "spiritual needs\n",
      "oulu fi\n",
      "pa ques\n",
      "jason smith\n",
      "things exist\n",
      "jasons atlastele\n",
      " \n",
      "Concept 43:\n",
      "darin johnson\n",
      "djohnson ucsd\n",
      "gay christians\n",
      "sex christianity\n",
      "new christian\n",
      "churches remind\n",
      "gay churches\n",
      "gay churches remind\n",
      "like ask\n",
      "would like ask\n",
      " \n",
      "Concept 44:\n",
      "virgin mary\n",
      "new christian\n",
      "like ask\n",
      "would like ask\n",
      "question virgin\n",
      "question virgin mary\n",
      "shell oil\n",
      "questions new\n",
      "questions new christian\n",
      "would like\n",
      " \n",
      "Concept 45:\n",
      "midway uchicago\n",
      "noye midway\n",
      "noye midway uchicago\n",
      "especially christianity\n",
      "use drugs\n",
      "christianity nothing\n",
      "christianity nothing drug\n",
      "christians inject\n",
      "drugs escape\n",
      "drugs escape reality\n",
      " \n",
      "Concept 46:\n",
      "virgin mary\n",
      "question virgin\n",
      "question virgin mary\n",
      "darin johnson\n",
      "djohnson ucsd\n",
      "biblical support\n",
      "body soul\n",
      "sex christianity\n",
      "assumption blessed\n",
      "mnhcc cunyvm\n",
      " \n",
      "Concept 47:\n",
      "death penalty\n",
      "eng sun\n",
      "gchin ssf\n",
      "gchin ssf eng\n",
      "gchin ssf eng sun\n",
      "ssf eng\n",
      "ssf eng sun\n",
      "gary chin\n",
      "capital punishment\n",
      "ezekiel 18\n",
      " \n",
      "Concept 48:\n",
      "christian practices\n",
      "parallel mormon\n",
      "eng sun\n",
      "god one set\n",
      "god one set rules\n",
      "one set\n",
      "one set rules\n",
      "set rules\n",
      "mormon ceremonies\n",
      "practices parallel\n",
      " \n",
      "Concept 49:\n",
      "b1 ingr\n",
      "iaserv b1\n",
      "iaserv b1 ingr\n",
      "tcsteven iaserv\n",
      "tcsteven iaserv b1\n",
      "tcsteven iaserv b1 ingr\n",
      "todd stevens\n",
      "christian trait\n",
      "temper christian\n",
      "temper christian trait\n",
      " \n",
      "Concept 50:\n",
      "catholic liturgy\n",
      "palm sunday\n",
      "ohio state\n",
      "foolish foolish\n",
      "new things\n",
      "john murray\n",
      "christian trait\n",
      "temper christian\n",
      "temper christian trait\n",
      "acrid angry\n",
      " \n",
      "Concept 51:\n",
      "death penalty\n",
      "palm sunday\n",
      "catholic liturgy\n",
      "new things\n",
      "ohio state\n",
      "christian practices\n",
      "parallel mormon\n",
      "john murray\n",
      "god shaped\n",
      "mormon ceremonies\n",
      " \n",
      "Concept 52:\n",
      "death penalty\n",
      "b1 ingr\n",
      "iaserv b1\n",
      "iaserv b1 ingr\n",
      "tcsteven iaserv\n",
      "tcsteven iaserv b1\n",
      "tcsteven iaserv b1 ingr\n",
      "todd stevens\n",
      "israeli government\n",
      "although israeli\n",
      " \n",
      "Concept 53:\n",
      "death penalty\n",
      "others danger\n",
      "warning others\n",
      "warning others danger\n",
      "lonestar utsa\n",
      "lonestar utsa melinda\n",
      "lonestar utsa melinda hsu\n",
      "melinda hsu\n",
      "mhsu lonestar\n",
      "mhsu lonestar utsa\n",
      " \n",
      "Concept 54:\n",
      "death penalty\n",
      "death penalty revenge\n",
      "penalty revenge\n",
      "try refute\n",
      "every year\n",
      "acknosledge speaking\n",
      "acknosledge speaking small\n",
      "acknosledge speaking small piece\n",
      "acknosledge speaking small piece problem\n",
      "amount crime\n",
      " \n",
      "Concept 55:\n",
      "cell church\n",
      "brain washed\n",
      "indoctrinated parents\n",
      "spiritual needs\n",
      "become christian\n",
      "become christian indoctrinated\n",
      "become christian indoctrinated parents\n",
      "become christian indoctrinated parents probably\n",
      "christian indoctrinated\n",
      "christian indoctrinated parents\n",
      " \n",
      "Concept 56:\n",
      "although bodily\n",
      "although bodily assumption\n",
      "although bodily assumption basis\n",
      "although bodily assumption basis bible\n",
      "assumption basis\n",
      "assumption basis bible\n",
      "assumption basis bible carl\n",
      "assumption basis bible carl jung\n",
      "basis bible\n",
      "basis bible carl\n",
      " \n",
      "Concept 57:\n",
      "different language\n",
      "god punished\n",
      "modern day\n",
      "different species\n",
      "maybe different species\n",
      "giving us\n",
      "spirit talking\n",
      "cell church\n",
      "05 40\n",
      "article may 05 40\n",
      " \n",
      "Concept 58:\n",
      "put hell\n",
      "sun geno\n",
      "27 therefore\n",
      "27 therefore babies\n",
      "27 therefore babies born\n",
      "27 therefore babies born state\n",
      "babies born state\n",
      "babies born state die\n",
      "babies born state die cuf\n",
      "born state\n",
      " \n",
      "Concept 59:\n",
      "death penalty\n",
      "death penalty revenge\n",
      "penalty revenge\n",
      "try refute\n",
      "second coming\n",
      "spiritual needs\n",
      "central sun\n",
      "although bodily\n",
      "although bodily assumption\n",
      "although bodily assumption basis\n",
      " \n",
      "Concept 60:\n",
      "cell church\n",
      "capital punishment\n",
      "eternal marriage\n",
      "given marriage\n",
      "neither marry\n",
      "marry given\n",
      "marry given marriage\n",
      "neither marry given\n",
      "neither marry given marriage\n",
      "jon reid\n",
      " \n",
      "Concept 61:\n",
      "mitre org\n",
      "peter trei\n",
      "much deleted\n",
      "biz soil\n",
      "biz soil princeton\n",
      "soil princeton\n",
      "death penalty\n",
      "article may 05\n",
      "atheist prayer\n",
      "may 05\n",
      " \n",
      "Concept 62:\n",
      "dreams oobes\n",
      "body incidents\n",
      "dreams body\n",
      "dreams body incidents\n",
      "ethics apply\n",
      "different moral\n",
      "morally responsible\n",
      "morality applies\n",
      "dt4 hub\n",
      "dt4 hub ucsb\n",
      " \n",
      "Concept 63:\n",
      "lincoln laboratory\n",
      "rob steele\n",
      "capital punishment\n",
      "aaron binah\n",
      "aaron binah brandeis\n",
      "binah brandeis\n",
      "02173 617\n",
      "02173 617 981\n",
      "02173 617 981 2575\n",
      "02173 617 981 2575 lewis\n",
      " \n",
      "Concept 64:\n",
      "death penalty\n",
      "biz soil\n",
      "biz soil princeton\n",
      "soil princeton\n",
      "capital punishment\n",
      "god one set\n",
      "god one set rules\n",
      "one set\n",
      "one set rules\n",
      "set rules\n",
      " \n",
      "Concept 65:\n",
      "become atheists\n",
      "coptic church\n",
      "people become\n",
      "people become atheists\n",
      "nabil ayoub\n",
      "bill mayne\n",
      "gerry palo\n",
      "could choose\n",
      "capital punishment\n",
      "believed god\n",
      " \n",
      "Concept 66:\n",
      "mitre org\n",
      "peter trei\n",
      "much deleted\n",
      "bistromath mitre\n",
      "bistromath mitre org\n",
      "bistromath mitre org peter\n",
      "bistromath mitre org peter trei\n",
      "existed prior\n",
      "mitre org peter\n",
      "mitre org peter trei\n",
      " \n",
      "Concept 67:\n",
      "second coming\n",
      "futon webo\n",
      "futon webo dg\n",
      "webo dg\n",
      "definition religion\n",
      "legal definition\n",
      "legal definition religion\n",
      "guild org\n",
      "mmalt guild\n",
      "mmalt guild org\n",
      " \n",
      "Concept 68:\n",
      "lincoln laboratory\n",
      "rob steele\n",
      "traer paz\n",
      "venido traer\n",
      "venido traer paz\n",
      "02173 617\n",
      "02173 617 981\n",
      "02173 617 981 2575\n",
      "02173 617 981 2575 lewis\n",
      "203 us\n",
      " \n",
      "Concept 69:\n",
      "eternity hell hell\n",
      "hell hell\n",
      "guild org vic\n",
      "guild org vic kulikauskas\n",
      "mmalt guild org vic\n",
      "mmalt guild org vic kulikauskas\n",
      "org vic\n",
      "org vic kulikauskas\n",
      "vic kulikauskas\n",
      "vic mmalt\n",
      " \n",
      "Concept 70:\n",
      "capital punishment\n",
      "second coming\n",
      "keep peace\n",
      "physical body\n",
      "futon webo\n",
      "futon webo dg\n",
      "webo dg\n",
      "non violent\n",
      "non violent provisions\n",
      "violent provisions\n",
      " \n",
      "Concept 71:\n",
      "capital punishment\n",
      "god shaped\n",
      "lincoln laboratory\n",
      "rob steele\n",
      "gerry palo\n",
      "canterbury nz\n",
      "bill rea\n",
      "natural disaster\n",
      "repeated lives\n",
      "god shaped hole\n",
      " \n",
      "Concept 72:\n",
      "death penalty\n",
      "gifted one\n",
      "god shaped\n",
      "capital punishment\n",
      "god shaped hole\n",
      "shaped hole\n",
      "believe predestination\n",
      "arlut utexas\n",
      "tsd arlut\n",
      "tsd arlut utexas\n",
      " \n",
      "Concept 73:\n",
      "pregnancy rates\n",
      "abstinence education\n",
      "sex education\n",
      "non liberal\n",
      "joe kellett\n",
      "second coming\n",
      "bruce stephens\n",
      "abstinence related\n",
      "abstinence related curricula\n",
      "related curricula\n",
      " \n",
      "Concept 74:\n",
      "meaning importance\n",
      "canterbury nz\n",
      "austin ibm\n",
      "mussack austin\n",
      "mussack austin ibm\n",
      "bill rea\n",
      "natural disaster\n",
      "life meaning importance\n",
      "want meaning\n",
      "billion years\n",
      " \n",
      "Concept 75:\n",
      "matt5 19\n",
      "spiritual needs\n",
      "first day\n",
      "ten commandments\n",
      "weak faith\n",
      "us ability\n",
      "jesus say\n",
      "honor lord\n",
      "sexual relations\n",
      "life sexual\n",
      " \n",
      "Concept 76:\n",
      "much later\n",
      "jcj tellabs\n",
      "definition religion\n",
      "legal definition\n",
      "legal definition religion\n",
      "24 rtsg\n",
      "24 rtsg mot\n",
      "ak 24\n",
      "ak 24 rtsg\n",
      "ak 24 rtsg mot\n",
      " \n",
      "Concept 77:\n",
      "physical body\n",
      "austin ibm\n",
      "mussack austin\n",
      "mussack austin ibm\n",
      "resurrection sunday\n",
      "easter name\n",
      "easter name new\n",
      "easter name new testament\n",
      "easter name new testament double\n",
      "name new testament\n",
      " \n",
      "Concept 78:\n",
      "delab sintef\n",
      "larsen delab\n",
      "larsen delab sintef\n",
      "every language\n",
      "bible available\n",
      "traer paz\n",
      "venido traer\n",
      "venido traer paz\n",
      "sintef delab\n",
      "gerry palo\n",
      " \n",
      "Concept 79:\n",
      "cell church\n",
      "certain without\n",
      "shadow doubt\n",
      "sayeth lord\n",
      "thus sayeth\n",
      "thus sayeth lord\n",
      "jodfishe silver\n",
      "jodfishe silver joseph\n",
      "jodfishe silver joseph dale\n",
      "joseph dale\n",
      " \n",
      "Concept 80:\n",
      "private interpretation\n",
      "blood transfusion\n",
      "physical body\n",
      "spiritual needs\n",
      "holy spirit\n",
      "uts au\n",
      "gerry palo\n",
      "god love\n",
      "deon strydom\n",
      "mike hahn\n",
      " \n",
      "Concept 81:\n",
      "physical body\n",
      "great judgement\n",
      "new body\n",
      "resurrection dead\n",
      "always found confusing\n",
      "always found confusing nerve\n",
      "always found confusing nerve endings\n",
      "bible talks fires hell something\n",
      "body would flame\n",
      "body would flame hurt\n",
      " \n",
      "Concept 82:\n",
      "pregnancy rates\n",
      "abstinence education\n",
      "definition christianity\n",
      "private revelation\n",
      "sex education\n",
      "joe kellett\n",
      "non liberal\n",
      "jesus christ\n",
      "belief jesus\n",
      "immaculate conception\n",
      " \n",
      "Concept 83:\n",
      "catholic church\n",
      "definition religion\n",
      "legal definition\n",
      "legal definition religion\n",
      "definition christianity\n",
      "much later\n",
      "capital punishment\n",
      "us ability\n",
      "belief jesus\n",
      "god shaped\n",
      " \n",
      "Concept 84:\n",
      "jewish proselytism\n",
      "pregnancy rates\n",
      "god shaped\n",
      "abstinence education\n",
      "sex education\n",
      "non liberal\n",
      "genesis 15\n",
      "god shaped hole\n",
      "shaped hole\n",
      "new testament\n",
      " \n",
      "Concept 85:\n",
      "jodfishe silver\n",
      "jodfishe silver joseph\n",
      "jodfishe silver joseph dale\n",
      "joseph dale\n",
      "silver joseph\n",
      "silver joseph dale\n",
      "delab sintef\n",
      "larsen delab\n",
      "larsen delab sintef\n",
      "every language\n",
      " \n",
      "Concept 86:\n",
      "jcj tellabs\n",
      "definition religion\n",
      "legal definition\n",
      "legal definition religion\n",
      "sheila patterson\n",
      "second coming\n",
      "midway uchicago\n",
      "noye midway\n",
      "noye midway uchicago\n",
      "_christianity crisis_\n",
      " \n",
      "Concept 87:\n",
      "goes show\n",
      "ecn purdue\n",
      "evangelical fundamentalists\n",
      "wear black\n",
      "wear black leather\n",
      "wear black leather jacket\n",
      "jesus name\n",
      "black leather\n",
      "black leather jacket\n",
      "leather jacket\n",
      " \n",
      "Concept 88:\n",
      "cell church\n",
      "private interpretation\n",
      "question authority\n",
      "jcj tellabs\n",
      "cu nih\n",
      "jek cu\n",
      "jek cu nih\n",
      "programs athens\n",
      "exist three\n",
      "exist three forms\n",
      " \n",
      "Concept 89:\n",
      "jodfishe silver\n",
      "jodfishe silver joseph\n",
      "jodfishe silver joseph dale\n",
      "joseph dale\n",
      "silver joseph\n",
      "silver joseph dale\n",
      "timothy 17\n",
      "interpretation would\n",
      "john 27\n",
      "17 29\n",
      " \n",
      "Concept 90:\n",
      "definition religion\n",
      "legal definition\n",
      "legal definition religion\n",
      "joe kellett\n",
      "jodfishe silver\n",
      "jodfishe silver joseph\n",
      "jodfishe silver joseph dale\n",
      "joseph dale\n",
      "silver joseph\n",
      "silver joseph dale\n",
      " \n",
      "Concept 91:\n",
      "definition religion\n",
      "legal definition\n",
      "legal definition religion\n",
      "second coming\n",
      "private interpretation\n",
      "god one\n",
      "koresh second\n",
      "koresh second coming\n",
      "stan friesen\n",
      "swf stan\n",
      " \n",
      "Concept 92:\n",
      "holy spirit\n",
      "catholic church\n",
      "jesus christ\n",
      "jodfishe silver\n",
      "jodfishe silver joseph\n",
      "jodfishe silver joseph dale\n",
      "joseph dale\n",
      "silver joseph\n",
      "silver joseph dale\n",
      "father son\n",
      " \n",
      "Concept 93:\n",
      "online bible\n",
      "cell church\n",
      "never heard\n",
      "nus sg\n",
      "bible software\n",
      "online bible software\n",
      "people new\n",
      "people new testament\n",
      "dead sea\n",
      "ling siew\n",
      " \n",
      "Concept 94:\n",
      "holy spirit\n",
      "definition religion\n",
      "legal definition\n",
      "legal definition religion\n",
      "homosexuality issues christiani\n",
      "issues christiani\n",
      "online bible\n",
      "father son\n",
      "matt5 19\n",
      "jon noring\n",
      " \n",
      "Concept 95:\n",
      "question authority\n",
      "empty tomb\n",
      "husband wife\n",
      "wife husband\n",
      "sheila patterson\n",
      "gifted one\n",
      "dead sea\n",
      "dead sea scrolls\n",
      "sea scrolls\n",
      "guild org\n",
      " \n",
      "Concept 96:\n",
      "fred gilham\n",
      "csl sri\n",
      "gilham csl\n",
      "gilham csl sri\n",
      "war hell\n",
      "empty tomb\n",
      "politically correct\n",
      "according folly\n",
      "according folly lest\n",
      "answer fool\n",
      " \n",
      "Concept 97:\n",
      "peter 20\n",
      "private interpretation\n",
      "jewish proselytism\n",
      "catholic church poland\n",
      "church poland\n",
      "accepting jesus\n",
      "accepting jesus heart\n",
      "jesus heart\n",
      "pa ques\n",
      "two minds\n",
      " \n",
      "Concept 98:\n",
      "cell church\n",
      "definition religion\n",
      "legal definition\n",
      "legal definition religion\n",
      "jcj tellabs\n",
      "__ __\n",
      "jodfishe silver\n",
      "jodfishe silver joseph\n",
      "jodfishe silver joseph dale\n",
      "joseph dale\n",
      " \n",
      "Concept 99:\n",
      "definition christianity\n",
      "blood transfusion\n",
      "belief jesus\n",
      "early christians\n",
      "futon webo\n",
      "futon webo dg\n",
      "webo dg\n",
      "belief jesus christ\n",
      "catholic church definition\n",
      "church definition\n",
      " \n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "for i, comp in enumerate(lsa.components_): \n",
    "    termsInComp = zip (terms,comp)\n",
    "    sortedTerms =  sorted(termsInComp, key=lambda x: x[1], reverse=True) [:10]\n",
    "    print(\"Concept %d:\" % i )\n",
    "    for term in sortedTerms:\n",
    "        print(term[0])\n",
    "    print (\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Results: Interpration Of Extracted Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
